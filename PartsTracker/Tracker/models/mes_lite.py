"""
MES Lite Models - Core Manufacturing

Contains the Lite tier (49 features) manufacturing models:
- Enums: PartsStatus, OrdersStatus, WorkOrderStatus, APQPStage, ProcessStatus
- Manufacturing: PartTypes, Processes, Steps, ProcessStep, StepEdge, EdgeType
- Orders: Orders, WorkOrder, Parts
- Workflow: StepExecution

Models moved to mes_standard.py (Standard tier):
- Equipment: EquipmentType, Equipments
- Sampling: SamplingRuleSet, SamplingRule, SamplingRuleType, SamplingTriggerState,
            SamplingTriggerManager, SamplingAuditLog, SamplingAnalytics
- MeasurementDefinition

Note: Documents, ThreeDModel, and HeatMapAnnotations are in qms.py/dms.py
"""

import random

from django.contrib.contenttypes.fields import GenericRelation
from django.db import models
from django.utils import timezone

from PartsTrackerApp import settings
from Tracker.sampling import SamplingFallbackApplier

from .core import SecureModel, User, Companies, ClassificationLevel, ExternalAPIOrderIdentifier

# Import Standard tier models for backward compatibility within this module
# These are re-exported from __init__.py for external consumers
from .mes_standard import (
    SamplingRuleSet,
    SamplingRule,
    SamplingRuleType,
    SamplingTriggerState,
    SamplingTriggerManager,
    SamplingAuditLog,
    SamplingAnalytics,
)


# ===== ENUMS =====

class PartsStatus(models.TextChoices):
    """Status values for Parts as they move through manufacturing process"""
    # Before production starts
    PENDING = "PENDING", "Pending"  # Created, not yet started

    # Core flow
    IN_PROGRESS = "IN_PROGRESS", "In Progress"  # Actively being worked on
    AWAITING_QA = "AWAITING_QA", "Awaiting QA"  # Step done, waiting for inspection
    READY_FOR_NEXT_STEP = "READY FOR NEXT STEP", "Ready for next step"
    COMPLETED = "COMPLETED", "Completed"  # Fully passed all steps

    # Exceptions
    QUARANTINED = "QUARANTINED", "Quarantined"  # Temporarily flagged for QA review
    REWORK_NEEDED = "REWORK_NEEDED", "Rework Needed"  # Needs rework from QA or operator
    REWORK_IN_PROGRESS = "REWORK_IN_PROGRESS", "Rework In Progress"

    # Terminal statuses
    SCRAPPED = "SCRAPPED", "Scrapped"  # Rejected permanently
    CANCELLED = "CANCELLED", "Cancelled"  # Removed before production finished
    SHIPPED = "SHIPPED", "Shipped"  # Shipped to customer
    IN_STOCK = "IN_STOCK", "In Stock"  # Completed, in inventory
    AWAITING_PICKUP = "AWAITING_PICKUP", "Awaiting Pickup"  # Ready for customer pickup
    CORE_BANKED = "CORE_BANKED", "Core Banked"  # Reman: stored as core
    RMA_CLOSED = "RMA_CLOSED", "RMA Closed"  # Return completed


# ===== MODELS =====

class PartTypes(SecureModel):
    """
    Represents a type/category of part that can be associated with processes and orders.

    Each new change to a PartType results in version increment and a new database entry.
    Useful for maintaining a historical record of part definitions over time.
    """

    documents = GenericRelation('Tracker.Documents')
    """Optional Document related to this type of part"""

    name = models.CharField(max_length=50)
    """Name of the part type, e.g., 'Fuel Injector'."""

    ID_prefix = models.CharField(max_length=50, null=True, blank=True)
    """Optional prefix for autogenerated part IDs, e.g., 'FJ-'."""

    ERP_id = models.CharField(max_length=50, null=True, blank=True)

    # =========================================================================
    # ITAR / Export Control Fields (inherited by Parts of this type)
    # =========================================================================
    itar_controlled = models.BooleanField(
        default=False,
        help_text="Part type is ITAR-controlled defense article (22 CFR 121 USML)"
    )
    """Default ITAR status for all parts of this type."""

    eccn = models.CharField(
        max_length=20,
        blank=True,
        help_text="Default ECCN for parts of this type (e.g., EAR99, 9A004)"
    )
    """Default Export Control Classification Number inherited by parts."""

    usml_category = models.CharField(
        max_length=10,
        blank=True,
        help_text="USML Category if ITAR-controlled (e.g., IV, XI, XIX)"
    )
    """
    US Munitions List category for ITAR items:
    - IV: Launch vehicles, guided missiles, ballistic missiles
    - XI: Military electronics
    - XIX: Gas turbine engines and associated equipment
    """

    class Meta:
        verbose_name_plural = 'Part Types'
        verbose_name = 'Part Type'

    def __str__(self):
        """
        Returns a human-readable representation of the part type.
        """
        return self.name


class ProcessStatus(models.TextChoices):
    """Approval status for a Process."""
    DRAFT = 'draft', 'Draft'           # Editable, not available for production
    PENDING_APPROVAL = 'pending_approval', 'Pending Approval'  # Submitted, awaiting approval
    APPROVED = 'approved', 'Approved'  # Locked, available for work orders
    DEPRECATED = 'deprecated', 'Deprecated'  # Still works, but hidden from new orders


class Processes(SecureModel):
    """
    Defines a manufacturing process applied to a given part type.

    Each process consists of multiple sequential steps and may have remanufacturing logic.
    The model is versioned to preserve historical configurations via SecureModel.

    Processes have a status workflow: DRAFT → APPROVED → DEPRECATED
    - DRAFT: Editable, not available for work orders
    - APPROVED: Locked, available for work orders
    - DEPRECATED: Still usable by existing work orders, hidden from new ones
    """

    documents = GenericRelation('Tracker.Documents')
    """Optional Document related to this type of process"""

    name = models.CharField(max_length=50)
    """Name of the process, e.g., 'Assembly Line A'."""

    is_remanufactured = models.BooleanField(default=False)
    """Indicates whether this process is for remanufacturing existing parts."""

    part_type = models.ForeignKey(PartTypes, on_delete=models.CASCADE, related_name='processes')
    """ForeignKey to the PartType this process is associated with."""

    is_batch_process = models.BooleanField(default=False,
                                           help_text="If True, UI treats work order parts as a batch unit")
    """Indicates whether this process should be handled as batch-level tracking in the UI."""

    # ===== APPROVAL WORKFLOW (Phase 2 Workflow Engine) =====

    status = models.CharField(
        max_length=20,
        choices=ProcessStatus.choices,
        default=ProcessStatus.DRAFT,
        help_text="Controls editability and availability for work orders"
    )
    """Approval status - DRAFT processes are editable, APPROVED are locked."""

    CATEGORY_CHOICES = [
        ('manufacturing', 'Manufacturing'),
        ('quality', 'Quality'),
        ('maintenance', 'Maintenance'),
        ('npi', 'New Product Introduction'),
        ('document', 'Document Control'),
    ]
    category = models.CharField(
        max_length=20,
        choices=CATEGORY_CHOICES,
        default='manufacturing',
        help_text="Process category for workflow engine routing"
    )
    """Category classification for routing and reporting."""

    # Note: Lineage tracking uses SecureModel's `previous_version` field instead of a separate field.
    # This provides: version number, previous_version FK, is_current_version flag.

    change_description = models.TextField(
        null=True,
        blank=True,
        help_text="Description of changes from previous version (for approval review)"
    )
    """What changed in this version - shown to approvers for context."""

    approved_at = models.DateTimeField(null=True, blank=True)
    """When this process was approved for production use."""

    approved_by = models.ForeignKey(
        User,
        null=True,
        blank=True,
        on_delete=models.SET_NULL,
        related_name='approved_processes'
    )
    """User who approved this process."""

    class Meta:
        verbose_name_plural = 'Processes'
        verbose_name = 'Process'

    def __str__(self):
        """
        Returns a readable string showing the name, part type, and remanufacture flag.
        """
        return f"{self.name} {self.part_type}{' Reman' if self.is_remanufactured else ''}"

    # ===== APPROVAL & VERSIONING METHODS =====

    @property
    def is_editable(self):
        """Only DRAFT processes can be edited (not PENDING_APPROVAL, APPROVED, or DEPRECATED)."""
        return self.status == ProcessStatus.DRAFT

    def approve(self, user=None):
        """
        Approve this process for production use.

        Once approved, the process cannot be modified.
        Use create_new_version() to create an editable new version for changes.
        """
        if self.status not in (ProcessStatus.DRAFT, ProcessStatus.PENDING_APPROVAL):
            raise ValueError("Only draft or pending processes can be approved.")

        if self.process_steps.count() == 0:
            raise ValueError("Cannot approve process with no steps.")

        self.status = ProcessStatus.APPROVED
        self.approved_at = timezone.now()
        self.approved_by = user
        self.save()

        return self

    def submit_for_approval(self, user):
        """
        Submit this process for formal approval workflow.

        Creates an ApprovalRequest using the PROCESS_APPROVAL template.
        Transitions DRAFT → PENDING_APPROVAL. Process cannot be edited while pending.

        Args:
            user: The user submitting the process for approval

        Returns:
            ApprovalRequest: The created approval request

        Raises:
            ValueError: If process is not DRAFT or no steps defined or template not found
        """
        if self.status != ProcessStatus.DRAFT:
            raise ValueError("Only draft processes can be submitted for approval.")

        if self.process_steps.count() == 0:
            raise ValueError("Cannot submit process with no steps for approval.")

        # Get the PROCESS_APPROVAL template (filtered by tenant)
        from .models.core import ApprovalTemplate, ApprovalRequest
        try:
            template = ApprovalTemplate.objects.get(
                approval_type='PROCESS_APPROVAL',
                tenant=self.tenant
            )
        except ApprovalTemplate.DoesNotExist:
            raise ValueError("PROCESS_APPROVAL approval template not found. Please configure approval templates.")

        # Create approval request
        approval_request = ApprovalRequest.create_from_template(
            content_object=self,
            template=template,
            requested_by=user,
            reason=f"Process Approval: {self.name} (v{self.version})"
        )

        self.status = ProcessStatus.PENDING_APPROVAL
        self.save()

        return approval_request

    def reject_approval(self):
        """
        Reject approval and return to DRAFT for editing.

        Called when approval request is rejected.
        """
        if self.status != ProcessStatus.PENDING_APPROVAL:
            raise ValueError("Only pending processes can be rejected.")

        self.status = ProcessStatus.DRAFT
        self.save()

        return self

    def deprecate(self):
        """
        Mark process as deprecated.

        Deprecated processes can still be used by existing work orders,
        but won't appear in process selection for new work orders.
        """
        if self.status not in (ProcessStatus.APPROVED,):
            raise ValueError("Only approved processes can be deprecated.")

        self.status = ProcessStatus.DEPRECATED
        self.save()

        return self

    def create_new_version(self, user=None, change_description=None, **field_updates):
        """
        Create a new version of this process - LIGHTWEIGHT.

        This is the proper way to modify an APPROVED process:
        1. Creates new Process with incremented version, linked via previous_version
        2. Copies ProcessStep records (pointing to same Step nodes)
        3. Copies StepEdge records (routing structure)

        Steps themselves are NOT copied - they're shared between versions.
        Only when a step is actually modified does it get a new version.

        Args:
            user: User creating the new version
            change_description: What changed (shown to approvers)
            **field_updates: Additional field overrides for the new process

        Returns:
            New Process instance in DRAFT status
        """
        if not self.is_current_version:
            raise ValueError("Can only create new versions from current version")

        if self.status not in (ProcessStatus.APPROVED, ProcessStatus.DEPRECATED):
            raise ValueError("Can only version approved or deprecated processes. Edit drafts directly.")

        # Mark current version as not current
        self.is_current_version = False
        self.save()

        # Create new process version
        new_process = Processes.objects.create(
            name=self.name,
            part_type=self.part_type,
            description=getattr(self, 'description', ''),
            is_remanufactured=self.is_remanufactured,
            is_batch_process=self.is_batch_process,
            status=ProcessStatus.DRAFT,
            version=self.version + 1,
            previous_version=self,
            is_current_version=True,
            change_description=change_description,
            created_by=user,
            **field_updates,
        )

        # Copy ProcessStep records (lightweight - same Step references)
        for ps in self.process_steps.all():
            ProcessStep.objects.create(
                process=new_process,
                step=ps.step,  # Same step node - NOT copied
                order=ps.order,
                is_entry_point=ps.is_entry_point,
            )

        # Copy StepEdge records (lightweight - same Step references)
        for edge in self.step_edges.all():
            StepEdge.objects.create(
                process=new_process,
                from_step=edge.from_step,  # Same step nodes
                to_step=edge.to_step,
                edge_type=edge.edge_type,
                condition_measurement=edge.condition_measurement,
                condition_operator=edge.condition_operator,
                condition_value=edge.condition_value,
            )

        return new_process

    def duplicate(self, user=None, name_suffix=" (Copy)"):
        """
        Create a standalone copy of this process (no version linkage).

        Use this for creating a new independent process based on an existing one,
        e.g., copying a process to use as a template for a different part type.

        For modifying approved processes, use create_new_version() instead.
        """
        new_process = Processes.objects.create(
            name=f"{self.name}{name_suffix}",
            part_type=self.part_type,
            is_remanufactured=self.is_remanufactured,
            is_batch_process=self.is_batch_process,
            status=ProcessStatus.DRAFT,
            # No previous_version - standalone copy
        )

        # Copy ProcessStep records (references same steps)
        for ps in self.process_steps.all():
            ProcessStep.objects.create(
                process=new_process,
                step=ps.step,
                order=ps.order,
                is_entry_point=ps.is_entry_point,
            )

        # Copy StepEdge records
        for edge in self.step_edges.all():
            StepEdge.objects.create(
                process=new_process,
                from_step=edge.from_step,
                to_step=edge.to_step,
                edge_type=edge.edge_type,
                condition_measurement=edge.condition_measurement,
                condition_operator=edge.condition_operator,
                condition_value=edge.condition_value,
            )

        return new_process

    def get_steps_ordered(self):
        """Get steps in order for this process via ProcessStep junction."""
        return Steps.objects.filter(
            process_memberships__process=self
        ).order_by('process_memberships__order')

    def get_entry_step(self):
        """Get the entry point step for this process."""
        ps = self.process_steps.filter(is_entry_point=True).first()
        return ps.step if ps else None

    def get_step_edges_from(self, step):
        """Get all outgoing edges from a step in this process."""
        return self.step_edges.filter(from_step=step)

    def get_next_step(self, current_step, edge_type='default'):
        """Get the next step for a given edge type."""
        edge = self.step_edges.filter(
            from_step=current_step,
            edge_type=edge_type
        ).first()
        return edge.to_step if edge else None

    @classmethod
    def get_available(cls, part_type=None):
        """Get processes available for new work orders (APPROVED only, current versions)."""
        qs = cls.objects.filter(status=ProcessStatus.APPROVED, is_current_version=True)
        if part_type:
            qs = qs.filter(part_type=part_type)
        return qs.order_by('name')


class MeasurementDefinition(SecureModel):
    """
    Defines a measurement specification for a step, with tolerances.

    Used for quality inspection and SPC (Statistical Process Control).
    """
    step = models.ForeignKey(
        "Steps",
        on_delete=models.CASCADE,
        related_name="measurement_definitions"
    )
    label = models.CharField(max_length=100)  # e.g. "Outer Diameter"
    type = models.CharField(
        max_length=20,
        choices=[("NUMERIC", "Numeric"), ("PASS_FAIL", "Pass/Fail")],
    )
    unit = models.CharField(max_length=50, blank=True)  # e.g. "mm", "psi"
    nominal = models.DecimalField(null=True, blank=True, decimal_places=6, max_digits=9)
    upper_tol = models.DecimalField(null=True, blank=True, decimal_places=6, max_digits=9)
    lower_tol = models.DecimalField(null=True, blank=True, decimal_places=6, max_digits=9)
    required = models.BooleanField(default=True)


class StepMeasurementRequirement(models.Model):
    """
    Through model linking Steps to MeasurementDefinition with Control Plan metadata.

    Allows per-step configuration of measurements including sequence, mandatory status,
    and tolerance overrides for Control Plan compliance.
    """
    step = models.ForeignKey('Steps', on_delete=models.CASCADE)
    measurement = models.ForeignKey(MeasurementDefinition, on_delete=models.CASCADE)

    # Control Plan fields
    is_mandatory = models.BooleanField(default=True, help_text="Must be recorded to advance step")
    sequence = models.PositiveIntegerField(default=0, help_text="Display/collection order")
    characteristic_number = models.CharField(max_length=20, blank=True, help_text="Balloon number on drawing")

    # Per-step tolerance overrides (null = use MeasurementDefinition defaults)
    tolerance_upper_override = models.FloatField(null=True, blank=True)
    tolerance_lower_override = models.FloatField(null=True, blank=True)

    class Meta:
        ordering = ['sequence']
        unique_together = ['step', 'measurement']

    def __str__(self):
        return f"{self.step.name} - {self.measurement.label}"


class Steps(SecureModel):
    """
    Represents a step definition (node) in a manufacturing workflow.

    Steps are independent entities that can be shared across multiple process versions.
    The relationship between steps and processes is managed via ProcessStep (junction)
    and StepEdge (routing) tables, enabling:
    - Lightweight process versioning (copy edges, not nodes)
    - Step reuse across process versions
    - Clean separation of step behavior from process structure

    Note: Order and routing are now defined at the process level via ProcessStep and StepEdge.
    """

    name = models.CharField(max_length=50)
    """Name of the step, e.g., 'Inspection', 'Assembly'."""

    pass_threshold = models.FloatField(default=1.0)
    """Threshold for pass/fail determination."""

    documents = GenericRelation('Tracker.Documents')
    """Optional documents related to this step."""

    expected_duration = models.DurationField(null=True, blank=True)
    """The estimated time this step is expected to take."""

    description = models.TextField(null=True, blank=True)
    """Optional human-readable explanation of what this step entails."""

    part_type = models.ForeignKey(PartTypes, related_name='steps', on_delete=models.PROTECT)
    """Reference to the `PartTypes` this step applies to. Used for filtering and scoping."""

    # ===== QA & SAMPLING =====

    block_on_quarantine = models.BooleanField(default=False)
    """If True, parts cannot advance from this step while quarantined."""

    requires_qa_signoff = models.BooleanField(default=False)
    """If True, QA approval is required to advance from this step."""

    notification_users = models.ManyToManyField(User, related_name='notification_users', blank=True)
    """Users to notify when parts reach this step."""

    required_measurements = models.ManyToManyField(
        MeasurementDefinition, through='StepMeasurementRequirement', blank=True,
        related_name="required_on_steps",
        help_text="Measurements that must be collected during this step"
    )

    sampling_required = models.BooleanField(default=False)
    """Whether this step requires sampling for quality control."""

    min_sampling_rate = models.FloatField(
        default=0.0,
        help_text="Minimum % of parts that must be sampled at this step"
    )

    # ===== FIRST PIECE INSPECTION =====

    requires_first_piece_inspection = models.BooleanField(
        default=False,
        help_text="If True, first part of each work order at this step requires FPI before others can proceed"
    )
    """
    First Piece Inspection (FPI) verifies setup correctness at the start of production.
    When enabled:
    - First part reaching this step for a work order is flagged for FPI
    - Other parts are blocked until FPI passes
    - FPI pass unlocks production for remaining parts
    """

    FPI_SCOPE_CHOICES = [
        ('per_workorder', 'Per Work Order'),
        ('per_shift', 'Per Shift'),
        ('per_equipment', 'Per Equipment'),
        ('per_operator', 'Per Operator'),
    ]
    fpi_scope = models.CharField(
        max_length=20,
        choices=FPI_SCOPE_CHOICES,
        default='per_workorder',
        help_text="Scope at which FPI applies"
    )

    # ===== WORKFLOW CONTROL =====

    block_on_measurement_failure = models.BooleanField(
        default=False,
        help_text="If True, parts cannot advance if any measurement is out of spec"
    )

    override_expiry_hours = models.PositiveIntegerField(
        default=24,
        help_text="Hours until an override expires and must be re-approved"
    )

    undo_window_minutes = models.PositiveIntegerField(
        default=15,
        help_text="Minutes during which a step completion can be undone"
    )

    rollback_requires_approval = models.BooleanField(
        default=True,
        help_text="Whether rolling back this step requires supervisor approval"
    )

    requires_batch_completion = models.BooleanField(
        default=False,
        help_text="If True, all parts in batch must be ready before any can advance"
    )

    # ===== STEP TYPE (Visual representation in flow editor) =====

    STEP_TYPE_CHOICES = [
        ('task', 'Task'),
        ('start', 'Start'),
        ('decision', 'Decision'),
        ('rework', 'Rework'),
        ('timer', 'Timer/Wait'),
        ('terminal', 'Terminal'),
    ]
    step_type = models.CharField(
        max_length=20,
        choices=STEP_TYPE_CHOICES,
        default='task',
        help_text="Visual type for flow editor."
    )

    # ===== DECISION BEHAVIOR =====

    is_decision_point = models.BooleanField(default=False)
    """If True, this step routes parts based on a decision (QA result, measurement, or manual)."""

    DECISION_TYPE_CHOICES = [
        ('qa_result', 'Based on QA Pass/Fail'),
        ('measurement', 'Based on Measurement Threshold'),
        ('manual', 'Manual Operator Selection'),
    ]
    decision_type = models.CharField(max_length=20, choices=DECISION_TYPE_CHOICES, blank=True)
    """Type of decision logic used at this step. Routing is defined via StepEdge."""

    # ===== TERMINAL STEP SUPPORT =====

    is_terminal = models.BooleanField(default=False)
    """If True, this is an endpoint - parts completing this step are finished."""

    TERMINAL_STATUS_CHOICES = [
        ('completed', 'Completed Successfully'),
        ('shipped', 'Shipped to Customer'),
        ('stock', 'Put into Inventory'),
        ('scrapped', 'Scrapped'),
        ('returned', 'Returned to Supplier'),
        ('awaiting_pickup', 'Awaiting Customer Pickup'),
        ('core_banked', 'Core Banked'),
        ('rma_closed', 'RMA Closed'),
    ]
    terminal_status = models.CharField(max_length=20, choices=TERMINAL_STATUS_CHOICES, blank=True)
    """Final status to assign to parts reaching this terminal step."""

    # ===== CYCLE CONTROL (for rework loops) =====

    max_visits = models.PositiveIntegerField(
        null=True, blank=True,
        help_text="Max times a part can visit this step. Null = unlimited."
    )
    """Escalation routing when exceeded is defined via StepEdge with type='escalation'."""

    REVISIT_ASSIGNMENT_CHOICES = [
        ('any', 'Any Qualified Operator'),
        ('same', 'Same as Previous'),
        ('different', 'Different Operator'),
        ('role', 'Specific Role'),
    ]
    revisit_assignment = models.CharField(
        max_length=20, choices=REVISIT_ASSIGNMENT_CHOICES, default='any'
    )
    revisit_role = models.ForeignKey(
        'auth.Group', null=True, blank=True,
        on_delete=models.SET_NULL,
        help_text="Required role when revisit_assignment='role'"
    )

    class Meta:
        verbose_name_plural = 'Steps'
        verbose_name = 'Step'
        ordering = ['part_type', 'name']

    def __str__(self):
        return f"{self.name} ({self.part_type.name})"

    def get_processes(self):
        """Get all processes that include this step."""
        return Processes.objects.filter(process_steps__step=self).distinct()

    def get_resolved_sampling_rules(self):
        """Get complete resolved sampling rules for this step"""
        # Get active primary ruleset
        primary_ruleset = self.sampling_ruleset.filter(is_fallback=False, active=True).order_by("-version").first()

        fallback_ruleset = None
        if primary_ruleset and primary_ruleset.fallback_ruleset:
            fallback_ruleset = primary_ruleset.fallback_ruleset

        return {'active_ruleset': {'id': primary_ruleset.id if primary_ruleset else None,
                                   'name': primary_ruleset.name if primary_ruleset else None, 'rules': list(
                primary_ruleset.rules.all().values('id', 'rule_type', 'value', 'order')) if primary_ruleset else [],
                                   'fallback_threshold': primary_ruleset.fallback_threshold if primary_ruleset else None,
                                   'fallback_duration': primary_ruleset.fallback_duration if primary_ruleset else None},
                'fallback_ruleset': {'id': fallback_ruleset.id if fallback_ruleset else None,
                                     'name': fallback_ruleset.name if fallback_ruleset else None, 'rules': list(
                        fallback_ruleset.rules.all().values('id', 'rule_type', 'value',
                                                            'order')) if fallback_ruleset else []} if fallback_ruleset else None}

    def apply_sampling_rules_update(self, rules_data, process=None, fallback_rules_data=None, fallback_threshold=None,
                                    fallback_duration=None, user=None):
        """Apply sampling rules update with proper versioning and activation.

        Args:
            rules_data: Sampling rules configuration
            process: Optional Process context for the rules (steps can be in multiple processes)
            fallback_rules_data: Optional fallback rules
            fallback_threshold: Threshold for fallback activation
            fallback_duration: Duration for fallback
            user: User making the update
        """
        from django.db import transaction

        with transaction.atomic():
            # Archive existing rulesets
            self.sampling_ruleset.filter(active=True).update(active=False, archived=True)

            # Create fallback ruleset first if provided
            fallback_ruleset = None
            if fallback_rules_data:
                fallback_ruleset = SamplingRuleSet.create_with_rules(part_type=self.part_type, process=process,
                                                                     step=self, name=f"Fallback for Step {self.id}",
                                                                     rules=fallback_rules_data, created_by=user,
                                                                     origin="serializer-update", active=True,
                                                                     is_fallback=True)

            # Create main ruleset
            main_ruleset = SamplingRuleSet.create_with_rules(part_type=self.part_type, process=process, step=self,
                                                             name=f"Rules for Step {self.id}", rules=rules_data,
                                                             fallback_ruleset=fallback_ruleset,
                                                             fallback_threshold=fallback_threshold,
                                                             fallback_duration=fallback_duration, created_by=user,
                                                             origin="serializer-update", active=True, is_fallback=False)

            # Re-evaluate sampling for any active parts at this step
            active_parts = Parts.objects.filter(step=self,
                                                part_status__in=[PartsStatus.PENDING, PartsStatus.IN_PROGRESS])

            if active_parts.exists():
                self._reevaluate_parts_sampling(list(active_parts))

            return main_ruleset

    def _reevaluate_parts_sampling(self, parts_list):
        """Re-evaluate sampling for list of parts after rule changes"""
        updates = []
        for part in parts_list:
            evaluator = SamplingFallbackApplier(part=part)
            result = evaluator.evaluate()

            part.requires_sampling = result.get("requires_sampling", False)
            part.sampling_rule = result.get("rule")
            part.sampling_ruleset = result.get("ruleset")
            part.sampling_context = result.get("context", {})
            updates.append(part)

        # Bulk update for efficiency
        Parts.objects.bulk_update(updates,
                                  ["requires_sampling", "sampling_rule", "sampling_ruleset", "sampling_context"])

    def update_sampling_rules(self, rules_data, process=None, fallback_rules_data=None, fallback_threshold=None,
                              fallback_duration=None, user=None):
        """Update sampling rules for this step.

        Args:
            rules_data: Sampling rules configuration
            process: Optional Process context for the rules
            fallback_rules_data: Optional fallback rules
            fallback_threshold: Threshold for fallback activation
            fallback_duration: Duration for fallback
            user: User making the update
        """
        from django.db import transaction

        with transaction.atomic():
            # Get or create primary ruleset
            primary_ruleset = SamplingRuleSet.objects.filter(step=self, part_type=self.part_type, active=True,
                                                             is_fallback=False).first()

            if primary_ruleset:
                # Supersede existing ruleset
                new_ruleset = primary_ruleset.supersede_with(name=f"{self.name} Rules v{primary_ruleset.version + 1}",
                                                             rules=rules_data, created_by=user)
            else:
                # Create new ruleset
                new_ruleset = SamplingRuleSet.create_with_rules(part_type=self.part_type, process=process,
                                                                step=self, name=f"{self.name} Rules v1",
                                                                rules=rules_data, created_by=user)

            # Handle fallback ruleset if provided
            if fallback_rules_data:
                fallback_ruleset = SamplingRuleSet.create_with_rules(part_type=self.part_type, process=process,
                                                                     step=self, name=f"{self.name} Fallback Rules v1",
                                                                     rules=fallback_rules_data, created_by=user,
                                                                     is_fallback=True)

                # Link fallback to primary
                new_ruleset.fallback_ruleset = fallback_ruleset
                new_ruleset.fallback_threshold = fallback_threshold
                new_ruleset.fallback_duration = fallback_duration
                new_ruleset.save()

            return new_ruleset

    def can_advance_step(self, work_order, step):
        """Fixed method with proper field references"""
        parts = Parts.objects.filter(work_order=work_order, step=step)
        ready_for_next = parts.filter(part_status=PartsStatus.READY_FOR_NEXT_STEP).count()
        total = parts.count()

        if step.block_on_quarantine and parts.filter(part_status='QUARANTINED').exists():
            return False

        # For batch processing, pass threshold should check parts ready to advance
        if ready_for_next / total < step.pass_threshold:
            return False

        # Import here to avoid circular import
        from .qms import QaApproval
        if step.requires_qa_signoff and not QaApproval.objects.filter(step=step, work_order=work_order).exists():
            return False

        # Check First Piece Inspection requirement
        if step.requires_first_piece_inspection:
            fpi_status = step.get_fpi_status(work_order)
            if fpi_status['status'] != 'PASSED':
                return False

        return True

    def get_fpi_status(self, work_order):
        """
        Get First Piece Inspection status for this step and work order.

        Returns dict with:
        - status: 'NOT_REQUIRED' | 'PENDING' | 'PASSED' | 'FAILED' | 'WAIVED'
        - fpi_record_id: UUID of the FPIRecord (if any)
        - designated_part_id: UUID of the designated part (if any)
        - blocked_parts_count: Number of parts waiting for FPI to pass
        """
        from .qms import FPIRecord, FPIStatus

        if not self.requires_first_piece_inspection:
            return {
                'status': 'NOT_REQUIRED',
                'fpi_record_id': None,
                'designated_part_id': None,
                'blocked_parts_count': 0
            }

        # Find FPI records for this (work_order, step) using the dedicated FPIRecord model
        fpi_records = FPIRecord.objects.filter(
            work_order=work_order,
            step=self,
            archived=False
        ).order_by('-created_at')

        # Check for passed or waived FPI
        passed_fpi = fpi_records.filter(status__in=[FPIStatus.PASSED, FPIStatus.WAIVED]).first()
        if passed_fpi:
            return {
                'status': 'PASSED' if passed_fpi.status == FPIStatus.PASSED else 'WAIVED',
                'fpi_record_id': str(passed_fpi.id),
                'designated_part_id': str(passed_fpi.designated_part_id) if passed_fpi.designated_part_id else None,
                'blocked_parts_count': 0
            }

        # Check for failed FPI (most recent)
        failed_fpi = fpi_records.filter(status=FPIStatus.FAILED).first()
        if failed_fpi:
            # Count parts waiting at this step
            blocked_count = Parts.objects.filter(
                work_order=work_order,
                step=self
            ).count()

            return {
                'status': 'FAILED',
                'fpi_record_id': str(failed_fpi.id),
                'designated_part_id': str(failed_fpi.designated_part_id) if failed_fpi.designated_part_id else None,
                'blocked_parts_count': blocked_count
            }

        # Check for pending FPI
        pending_fpi = fpi_records.filter(status=FPIStatus.PENDING).first()
        blocked_count = Parts.objects.filter(work_order=work_order, step=self).count()

        return {
            'status': 'PENDING',
            'fpi_record_id': str(pending_fpi.id) if pending_fpi else None,
            'designated_part_id': str(pending_fpi.designated_part_id) if pending_fpi and pending_fpi.designated_part_id else None,
            'blocked_parts_count': blocked_count
        }

    def needs_fpi(self, work_order):
        """
        Check if this step still needs a First Piece Inspection for the given work order.

        Returns True if:
        - Step requires FPI
        - No passing FPI exists yet for this (work_order, step)
        """
        if not self.requires_first_piece_inspection:
            return False

        from .qms import FPIRecord, FPIStatus

        # Check if FPI already passed or waived
        return not FPIRecord.objects.filter(
            work_order=work_order,
            step=self,
            status__in=[FPIStatus.PASSED, FPIStatus.WAIVED],
            archived=False
        ).exists()

    def get_active_sampling_ruleset(self, part_type):
        """Get the currently active ruleset for this step"""
        return SamplingRuleSet.objects.filter(step=self, part_type=part_type, active=True, is_fallback=False).order_by(
            "version").last()

    def validate_sampling_coverage(self, work_order):
        """Ensure minimum sampling rate is met"""
        total_parts = Parts.objects.filter(work_order=work_order, step=self).count()
        sampled_parts = Parts.objects.filter(work_order=work_order, step=self, requires_sampling=True).count()

        actual_rate = (sampled_parts / total_parts * 100) if total_parts > 0 else 0
        return actual_rate >= self.min_sampling_rate

    def get_sampling_coverage_report(self, work_order):
        """Generate sampling coverage report for this step"""
        # Import here to avoid circular import
        from .qms import QualityReports

        total_parts = Parts.objects.filter(work_order=work_order, step=self).count()
        sampled_parts = Parts.objects.filter(work_order=work_order, step=self, requires_sampling=True).count()

        inspected_parts = QualityReports.objects.filter(part__work_order=work_order, step=self).count()

        return {'total_parts': total_parts, 'sampled_parts': sampled_parts, 'inspected_parts': inspected_parts,
                'sampling_rate': (sampled_parts / total_parts * 100) if total_parts > 0 else 0,
                'inspection_completion': (inspected_parts / sampled_parts * 100) if sampled_parts > 0 else 0,
                'meets_minimum': self.validate_sampling_coverage(work_order)}

    def can_advance_from_step(self, step_execution, work_order):
        """
        Comprehensive gating function for step advancement.

        Checks all requirements that must be satisfied before a part can advance
        from this step. Returns a tuple of (can_advance: bool, blockers: list).

        Blockers list contains human-readable descriptions of what's blocking advancement.

        Checks performed:
        1. Sampling requirement (QualityReport exists if required)
        2. QA signoff (QaApproval exists if required)
        3. FPI status (passed if required)
        4. Mandatory measurements (all recorded and within spec)
        5. Hard blocks (quarantine, regulatory holds)
        6. Override status (valid override if blocked)

        Args:
            step_execution: StepExecution instance for the part at this step
            work_order: WorkOrder instance

        Returns:
            tuple: (can_advance: bool, blockers: list of str)
        """
        from .qms import QaApproval, QualityReports, FPIRecord, StepOverride

        blockers = []
        part = step_execution.part

        # 1. Check quarantine status
        if part.part_status == PartsStatus.QUARANTINED:
            if self.block_on_quarantine:
                blockers.append("Part is quarantined and step blocks on quarantine")

        # 2. Check QA signoff requirement
        if self.requires_qa_signoff:
            qa_approval = QaApproval.objects.filter(
                step=self,
                work_order=work_order
            ).first()
            if not qa_approval:
                blockers.append("QA signoff required but not received")

        # 3. Check FPI requirement
        if self.requires_first_piece_inspection:
            fpi_status = self.get_fpi_status(work_order)
            if fpi_status['status'] not in ('PASSED', 'WAIVED', 'NOT_REQUIRED'):
                blockers.append(f"First Piece Inspection required: {fpi_status['status']}")

        # 4. Check sampling requirement
        if self.sampling_required and part.requires_sampling:
            quality_report = QualityReports.objects.filter(
                part=part,
                step=self,
                archived=False
            ).first()
            if not quality_report:
                blockers.append("Sampling inspection required but not completed")
            elif quality_report.status == 'FAIL':
                blockers.append("Sampling inspection failed - disposition required")

        # 5. Check mandatory measurements
        if hasattr(self, 'block_on_measurement_failure') and self.block_on_measurement_failure:
            from .qms import StepExecutionMeasurement
            failed_measurements = StepExecutionMeasurement.objects.filter(
                step_execution=step_execution,
                is_within_spec=False
            ).exists()
            if failed_measurements:
                blockers.append("One or more measurements are out of specification")

            # Also check if all required measurements are recorded
            required_measurement_ids = list(
                self.required_measurements.values_list('id', flat=True)
            )
            if required_measurement_ids:
                recorded_ids = set(
                    StepExecutionMeasurement.objects.filter(
                        step_execution=step_execution
                    ).values_list('measurement_definition_id', flat=True)
                )
                missing = set(required_measurement_ids) - recorded_ids
                if missing:
                    blockers.append(f"Missing {len(missing)} required measurement(s)")

        # 6. Check StepRequirement model entries
        for req in self.requirements.filter(is_mandatory=True, archived=False):
            if not req.is_satisfied(step_execution):
                blockers.append(f"Requirement not met: {req.name}")

        # 7. Check for valid overrides that could clear blocks
        if blockers:
            valid_overrides = StepOverride.objects.filter(
                step_execution=step_execution,
                status='approved',
                used=False
            )
            # Check each blocker against overrides
            override_types = set(valid_overrides.values_list('block_type', flat=True))
            remaining_blockers = []

            for blocker in blockers:
                # Map blocker message to block type
                can_override = False
                if 'quarantine' in blocker.lower() and 'quarantine' in override_types:
                    can_override = True
                elif 'qa signoff' in blocker.lower() and 'qa_signoff' in override_types:
                    can_override = True
                elif 'first piece' in blocker.lower() and 'fpi_required' in override_types:
                    can_override = True
                elif 'sampling' in blocker.lower() and 'sampling_required' in override_types:
                    can_override = True
                elif 'measurement' in blocker.lower() and 'measurement_failed' in override_types:
                    can_override = True

                if not can_override:
                    remaining_blockers.append(blocker)

            blockers = remaining_blockers

        return (len(blockers) == 0, blockers)


class DecisionDataMissing(ValueError):
    """Raised when required data for a decision point is missing."""
    pass


# ===== STEP REQUIREMENTS =====

class RequirementType(models.TextChoices):
    """Types of requirements for step advancement."""
    MEASUREMENT = 'measurement', 'Measurement'
    DOCUMENT = 'document', 'Document'
    SIGNOFF = 'signoff', 'Signoff'
    EQUIPMENT_CHECK = 'equipment_check', 'Equipment Check'
    MATERIAL_SCAN = 'material_scan', 'Material Scan'
    TRAINING_VALID = 'training_valid', 'Training Valid'
    CALIBRATION_VALID = 'calibration_valid', 'Calibration Valid'
    FPI_PASSED = 'fpi_passed', 'FPI Passed'
    QA_APPROVAL = 'qa_approval', 'QA Approval'
    CUSTOM = 'custom', 'Custom'


class StepRequirement(SecureModel):
    """
    Defines a requirement that must be satisfied before advancing from a step.

    This model provides a flexible, extensible way to define step gating rules.
    Each requirement has a type, configuration, and mandatory flag.

    Types include:
    - measurement: Specific measurement must be recorded
    - document: Specific document type must be attached
    - signoff: Requires user signoff (supervisor, QA, etc.)
    - equipment_check: Equipment must be operational/calibrated
    - material_scan: Material lot must be scanned/verified
    - training_valid: Operator must have valid training
    - calibration_valid: Equipment calibration must be current
    - fpi_passed: First Piece Inspection must pass
    - qa_approval: QA approval must be recorded
    - custom: Custom logic (defined in config)
    """

    step = models.ForeignKey(
        Steps,
        on_delete=models.CASCADE,
        related_name='requirements'
    )
    requirement_type = models.CharField(
        max_length=30,
        choices=RequirementType.choices,
        help_text='Type of requirement'
    )
    name = models.CharField(
        max_length=100,
        help_text='Short name for the requirement'
    )
    description = models.TextField(
        blank=True,
        help_text='Detailed description of the requirement'
    )
    is_mandatory = models.BooleanField(
        default=True,
        help_text='Whether this requirement must be satisfied to advance'
    )
    order = models.PositiveIntegerField(
        default=0,
        help_text='Display order within step'
    )
    config = models.JSONField(
        default=dict,
        help_text='Type-specific configuration (e.g., measurement IDs, document types)'
    )

    class Meta:
        verbose_name = 'Step Requirement'
        verbose_name_plural = 'Step Requirements'
        ordering = ['step', 'order']
        indexes = [
            models.Index(fields=['step', 'requirement_type']),
        ]

    def __str__(self):
        return f"{self.step.name}: {self.name}"

    def is_satisfied(self, step_execution):
        """
        Check if this requirement is satisfied for the given step execution.

        Args:
            step_execution: StepExecution instance to check

        Returns:
            bool: True if requirement is satisfied, False otherwise
        """
        from .qms import QaApproval, FPIRecord, StepExecutionMeasurement

        if self.requirement_type == RequirementType.MEASUREMENT:
            # Check if all configured measurements are recorded
            measurement_ids = self.config.get('measurement_ids', [])
            if not measurement_ids:
                return True
            recorded = StepExecutionMeasurement.objects.filter(
                step_execution=step_execution,
                measurement_definition_id__in=measurement_ids,
                is_within_spec=True
            ).values_list('measurement_definition_id', flat=True)
            return set(measurement_ids) == set(recorded)

        elif self.requirement_type == RequirementType.QA_APPROVAL:
            # Check if QA approval exists
            return QaApproval.objects.filter(
                step=step_execution.step,
                work_order=step_execution.part.work_order
            ).exists()

        elif self.requirement_type == RequirementType.FPI_PASSED:
            # Check if FPI passed for this work order/step
            fpi = FPIRecord.objects.filter(
                work_order=step_execution.part.work_order,
                step=step_execution.step,
                status='passed'
            ).first()
            return fpi is not None

        elif self.requirement_type == RequirementType.SIGNOFF:
            # Check if signoff recorded (via step execution completed_by)
            return step_execution.completed_by is not None

        # Default: assume satisfied for unhandled types
        return True


# ===== GRAPH STRUCTURE (Process-Step relationships) =====

class ProcessStep(models.Model):
    """
    Junction table linking Steps to Processes with ordering.

    This enables steps to be shared across process versions while maintaining
    process-specific ordering. When a process is versioned, only ProcessStep
    records are copied (lightweight), not the Step definitions themselves.

    Benefits:
    - Steps are only duplicated when actually modified
    - Process versioning is cheap (copy edges, not nodes)
    - Clean separation of step definition from process structure
    """
    process = models.ForeignKey(
        Processes,
        on_delete=models.CASCADE,
        related_name='process_steps'
    )
    step = models.ForeignKey(
        Steps,
        on_delete=models.CASCADE,
        related_name='process_memberships'
    )
    order = models.IntegerField(
        help_text="Position of this step within the process flow"
    )

    # Entry point marker (first step in flow)
    is_entry_point = models.BooleanField(
        default=False,
        help_text="If True, this is the starting step for new parts"
    )

    # Exit point marker (early completion path)
    is_exit_point = models.BooleanField(
        default=False,
        help_text="If True, this step can exit the process early (e.g., early ship)"
    )

    # Auto-advance control
    auto_advance = models.BooleanField(
        default=True,
        help_text="If True, parts auto-advance when step requirements are met"
    )

    class Meta:
        unique_together = [
            ('process', 'step'),  # Each step appears once per process
            ('process', 'order'),  # Each order position is unique per process
        ]
        ordering = ['process', 'order']

    def __str__(self):
        return f"{self.process.name} → Step {self.order}: {self.step.name}"


class EdgeType(models.TextChoices):
    """Types of edges between steps in a process flow."""
    DEFAULT = 'default', 'Default/Pass'  # Normal flow or pass condition
    ALTERNATE = 'alternate', 'Alternate/Fail'  # Fail condition or alternate path
    ESCALATION = 'escalation', 'Escalation'  # Max visits exceeded


class StepEdge(models.Model):
    """
    Directed edge between steps, scoped to a specific process version.

    This is the core of the DAG structure for workflow routing. Each process
    version has its own set of edges, allowing the same steps to have
    different routing in different process versions.

    Edge types:
    - DEFAULT: Normal flow, or "pass" path for decision points
    - ALTERNATE: "Fail" path or alternate condition
    - ESCALATION: Route taken when max_visits exceeded
    """
    process = models.ForeignKey(
        Processes,
        on_delete=models.CASCADE,
        related_name='step_edges'
    )
    from_step = models.ForeignKey(
        Steps,
        on_delete=models.CASCADE,
        related_name='outgoing_edges'
    )
    to_step = models.ForeignKey(
        Steps,
        on_delete=models.CASCADE,
        related_name='incoming_edges'
    )
    edge_type = models.CharField(
        max_length=20,
        choices=EdgeType.choices,
        default=EdgeType.DEFAULT
    )

    # For measurement-based decision routing (edge-level override)
    # If set, overrides the step's decision settings for this specific edge
    condition_measurement = models.ForeignKey(
        MeasurementDefinition,
        null=True,
        blank=True,
        on_delete=models.SET_NULL,
        related_name='condition_edges',
        help_text="Optional: measurement that triggers this edge"
    )
    condition_operator = models.CharField(
        max_length=10,
        choices=[
            ('gte', '>= (greater or equal)'),
            ('lte', '<= (less or equal)'),
            ('eq', '= (equal)'),
        ],
        blank=True
    )
    condition_value = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="Threshold value for measurement-based routing"
    )

    class Meta:
        # Allow multiple edge types between same steps (e.g., default + escalation)
        unique_together = [('process', 'from_step', 'to_step', 'edge_type')]
        ordering = ['process', 'from_step', 'edge_type']

    def __str__(self):
        return f"{self.process.name}: {self.from_step.name} --[{self.edge_type}]--> {self.to_step.name}"


class StepExecution(SecureModel):
    """
    Tracks a part's visit to a step - from entry to exit.

    This model provides richer lifecycle tracking than StepTransitionLog:
    - Tracks entry AND exit times (not just transition timestamp)
    - Records visit number for cycle counting (rework loops)
    - Captures decision results for branching workflows
    - Supports operator assignment rules

    Used by the workflow engine for:
    - WIP queries (who's working on what)
    - Cycle limit enforcement (max_visits)
    - Operator assignment (same/different/role rules)
    - Step duration analytics
    """

    part = models.ForeignKey(
        'Parts', on_delete=models.CASCADE,
        related_name='step_executions',
        help_text="The part being tracked through this step"
    )
    step = models.ForeignKey(
        Steps, on_delete=models.PROTECT,
        related_name='executions',
        help_text="The step being executed"
    )
    visit_number = models.PositiveIntegerField(
        default=1,
        help_text="Which visit this is (1st, 2nd, 3rd time at this step)"
    )

    # Entry tracking (set when part enters step)
    entered_at = models.DateTimeField(auto_now_add=True)
    assigned_to = models.ForeignKey(
        User, null=True, blank=True,
        on_delete=models.SET_NULL,
        related_name='assigned_step_executions',
        help_text="Operator assigned to this step execution"
    )

    # Exit tracking (set when part leaves step)
    exited_at = models.DateTimeField(null=True, blank=True)
    completed_by = models.ForeignKey(
        User, null=True, blank=True,
        on_delete=models.SET_NULL,
        related_name='completed_step_executions',
        help_text="Operator who completed this step"
    )
    next_step = models.ForeignKey(
        Steps, null=True, blank=True,
        on_delete=models.SET_NULL,
        related_name='incoming_executions',
        help_text="The step this part moved to (for audit trail)"
    )

    # Decision result (for branching steps)
    decision_result = models.CharField(
        max_length=50, blank=True,
        help_text="Result of decision: 'pass', 'fail', measurement value, etc."
    )

    # Workflow tracking fields
    started_at = models.DateTimeField(
        null=True, blank=True,
        help_text="When work actually started on this step"
    )
    needs_reassignment = models.BooleanField(
        default=False,
        help_text="Flag indicating operator reassignment is needed"
    )

    # FPI tracking
    is_fpi = models.BooleanField(
        default=False,
        help_text="Whether this execution is a First Piece Inspection"
    )
    FPI_STATUS_CHOICES = [
        ('not_required', 'Not Required'),
        ('pending', 'Pending'),
        ('passed', 'Passed'),
        ('failed', 'Failed'),
        ('waived', 'Waived'),
    ]
    fpi_status = models.CharField(
        max_length=20,
        choices=FPI_STATUS_CHOICES,
        default='not_required',
        help_text="First Piece Inspection status for this execution"
    )

    # Polymorphic subject support (future workflow engine)
    subject_content_type = models.ForeignKey(
        'contenttypes.ContentType',
        null=True, blank=True,
        on_delete=models.SET_NULL,
        help_text="Content type for polymorphic subject (future workflow engine)"
    )
    subject_id = models.UUIDField(
        null=True, blank=True,
        help_text="ID of the polymorphic subject"
    )

    # Status (updated choices)
    EXECUTION_STATUS_CHOICES = [
        ('pending', 'Pending'),
        ('claimed', 'Claimed'),
        ('in_progress', 'In Progress'),
        ('completed', 'Completed'),
        ('skipped', 'Skipped'),
        ('cancelled', 'Cancelled'),
        ('rolled_back', 'Rolled Back'),
    ]
    status = models.CharField(
        max_length=20, choices=EXECUTION_STATUS_CHOICES, default='pending'
    )

    class Meta:
        ordering = ['entered_at']
        verbose_name = 'Step Execution'
        verbose_name_plural = 'Step Executions'
        indexes = [
            models.Index(fields=['part', 'step']),
            models.Index(fields=['status', 'entered_at']),
            models.Index(fields=['assigned_to', 'status']),
        ]

    def __str__(self):
        return f"{self.part} at {self.step} (visit {self.visit_number})"

    @property
    def duration(self):
        """Time spent at this step, or None if still in progress."""
        if self.exited_at and self.entered_at:
            return self.exited_at - self.entered_at
        return None

    @classmethod
    def get_visit_count(cls, part, step):
        """Get how many times a part has visited a specific step."""
        return cls.objects.filter(part=part, step=step).count()

    @classmethod
    def get_visit_count_for_update(cls, part, step):
        """
        Get visit count with row-level locking to prevent race conditions.

        Use this when creating new StepExecution records to ensure
        accurate visit_number assignment under concurrent load.

        Must be called within a transaction (atomic block).
        """
        from django.db import transaction

        # Lock existing executions for this part/step to prevent concurrent inserts
        # from reading stale counts
        with transaction.atomic():
            locked_executions = list(
                cls.objects.select_for_update().filter(
                    part=part, step=step
                ).values_list('id', flat=True)
            )
            return len(locked_executions)

    @classmethod
    def get_current_execution(cls, part):
        """Get the current (active) execution for a part."""
        return cls.objects.filter(
            part=part,
            exited_at__isnull=True
        ).first()

    @classmethod
    def get_wip_at_step(cls, step):
        """Get all parts currently at a step (work in progress)."""
        return cls.objects.filter(
            step=step,
            status__in=['pending', 'in_progress']
        ).select_related('part', 'assigned_to')

    @classmethod
    def get_operator_workload(cls, user):
        """Get all active step executions assigned to an operator."""
        return cls.objects.filter(
            assigned_to=user,
            status__in=['pending', 'in_progress']
        ).select_related('part', 'step')


class OrdersStatus(models.TextChoices):
    RFI = 'RFI', 'RFI'
    PENDING = 'PENDING', "Pending"
    IN_PROGRESS = 'IN_PROGRESS', "In progress"
    COMPLETED = 'COMPLETED', "Completed"
    ON_HOLD = 'ON_HOLD', "On hold"
    CANCELLED = 'CANCELLED', "Cancelled"


class APQPStage(models.TextChoices):
    PLANNING = 'PLANNING', "Planning"
    PRODUCT_DESIGN_AND_DEVELOPMENT = 'PRODUCT DESIGN AND DEVELOPMENT', "Product design and development"
    PROCESS_DESIGN_AND_DEVELOPMENT = 'PROCESS DESIGN AND DEVELOPMENT', "Process and development"
    PRODUCT_AND_PROCESS_VALIDATION = 'PRODUCT AND PROCESS VALIDATION', "Product and process validation"
    PRODUCTION = 'PRODUCTION', "Production"


class OrderViewer(models.Model):
    """
    Through model tracking who can view an order and how they were granted access.

    Supports portal feature where customers can view order status.
    Tracks invitation metadata for audit trail.
    """
    class InvitationType(models.TextChoices):
        DIRECT = 'direct', 'Direct Invitation'
        COMPANY = 'company', 'Company Member'
        STAFF = 'staff', 'Staff Assigned'

    order = models.ForeignKey('Orders', on_delete=models.CASCADE)
    user = models.ForeignKey(User, on_delete=models.CASCADE)

    invitation_type = models.CharField(max_length=20, choices=InvitationType.choices, default=InvitationType.DIRECT)
    invited_by = models.ForeignKey(User, on_delete=models.SET_NULL, null=True, blank=True, related_name='order_invitations_sent')
    invited_at = models.DateTimeField(auto_now_add=True)
    expires_at = models.DateTimeField(null=True, blank=True, help_text="Optional expiration for temporary access")

    class Meta:
        unique_together = ['order', 'user']

    def __str__(self):
        return f"{self.user} can view {self.order}"

    @property
    def is_expired(self):
        if not self.expires_at:
            return False
        return timezone.now() > self.expires_at


class Orders(SecureModel):
    """
    Represents a production or delivery order submitted by a customer.

    Orders define the high-level context for a batch of parts tied to a customer and company.
    Supports lifecycle tracking via status, estimated deadlines, and soft-archiving for traceability.
    """

    order_number = models.CharField(
        max_length=20,
        blank=True,
        help_text="Auto-generated internal order number: ORD-YYYY-####"
    )
    """Internal order number for consistent reference, auto-generated on creation."""

    name = models.CharField(max_length=200)
    """Internal or customer-facing name for the order."""

    customer_note = models.TextField(null=True, blank=True)
    """Structured timeline of notes. Format: [timestamp | user | visibility]\\nmessage\\n---"""

    documents = GenericRelation('Tracker.Documents')
    """Optional documents associated with this order."""

    customer = models.ForeignKey('User', on_delete=models.SET_NULL, null=True, blank=True,
                                 related_name='customer_orders')
    """Optional link to the user who submitted or is responsible for the order."""

    viewers = models.ManyToManyField(
        'User', through='OrderViewer', through_fields=('order', 'user'),
        blank=True, related_name='viewable_orders'
    )
    """Additional users who can view this order (invited by customer or staff)."""

    company = models.ForeignKey('Companies', on_delete=models.SET_NULL, null=True, blank=True, related_name='orders')
    """Company the order is associated with (usually customer company)."""

    estimated_completion = models.DateField(null=True, blank=True)
    """Optional expected date of completion for this order."""

    original_completion_date = models.DateTimeField(null=True, blank=True)

    order_status = models.CharField(max_length=50, choices=OrdersStatus.choices, default=OrdersStatus.PENDING)
    """Current status of the order used to track its lifecycle."""

    # HubSpot Integration Fields
    current_hubspot_gate = models.ForeignKey("ExternalAPIOrderIdentifier", blank=True, null=True,
                                             on_delete=models.SET_NULL)
    """Optional field to track HubSpot pipeline status or stage."""

    hubspot_deal_id = models.CharField(max_length=60, null=True, blank=True, db_index=True)
    """HubSpot deal ID - NULL if order was created locally, not from HubSpot. Unique per tenant."""

    last_synced_hubspot_stage = models.CharField(max_length=100, null=True, blank=True)
    """Cached stage name from last sync."""

    hubspot_last_synced_at = models.DateTimeField(null=True, blank=True)
    """When this order was last synced from HubSpot - NULL if never synced or not a HubSpot order."""

    class Meta:
        verbose_name = 'Order'
        indexes = [
            models.Index(fields=['order_status', 'created_at'], name='orders_status_created_idx'),
            models.Index(fields=['customer', 'order_status'], name='orders_customer_status_idx'),
            models.Index(fields=['company', 'order_status'], name='orders_company_status_idx'),
        ]
        constraints = [
            models.UniqueConstraint(
                fields=['tenant', 'order_number'],
                condition=models.Q(order_number__isnull=False) & ~models.Q(order_number=''),
                name='orders_tenant_number_uniq'
            ),
            models.UniqueConstraint(
                fields=['tenant', 'hubspot_deal_id'],
                condition=models.Q(hubspot_deal_id__isnull=False) & ~models.Q(hubspot_deal_id=''),
                name='orders_tenant_hubspot_deal_uniq'
            ),
        ]

    def save(self, *args, **kwargs):
        is_update = self.pk is not None
        old_stage = None

        # Auto-generate order_number on creation
        if not self.order_number:
            self.order_number = self.generate_order_number(self.tenant)

        if is_update:
            try:
                old_stage = Orders.objects.get(pk=self.pk).current_hubspot_gate
            except Orders.DoesNotExist:
                pass

        super().save(*args, **kwargs)

        # Use mixin's helper to check if should push to HubSpot
        if is_update and self._should_push_to_hubspot(old_stage):
            # Queue async task to push to HubSpot
            from Tracker.tasks import update_hubspot_deal_stage_task
            update_hubspot_deal_stage_task.delay(
                self.hubspot_deal_id,
                self.current_hubspot_gate.id,
                self.id
            )

    @classmethod
    def generate_order_number(cls, tenant=None):
        """
        Generate a unique order number with race-condition protection.
        Format: ORD-YYYY-#### (e.g., ORD-2026-0001)
        """
        from django.utils import timezone
        from Tracker.utils.sequences import generate_next_sequence

        year = timezone.now().year
        prefix = f"ORD-{year}-"
        return generate_next_sequence(
            queryset=cls.objects,
            number_field='order_number',
            prefix=prefix,
            padding=4,
            tenant=tenant
        )

    def get_step_distribution(self, exclude_completed=True):
        """Get distribution of parts across steps for this order"""
        from django.db.models import Count

        queryset = self.parts.all()
        if exclude_completed:
            queryset = queryset.exclude(part_status=PartsStatus.COMPLETED)

        step_counts = queryset.values("step_id").annotate(count=Count("id"))

        # Get step names efficiently
        step_id_to_name = {step.id: step.name for step in
                           Steps.objects.filter(id__in=[s["step_id"] for s in step_counts])}

        return [{"id": step["step_id"], "name": step_id_to_name.get(step["step_id"], f"Step {step['step_id']}"),
                 "count": step["count"]} for step in step_counts]

    def push_to_hubspot(self):
        """Push order stage changes back to HubSpot."""
        if not self.hubspot_deal_id:
            return

        from Tracker.hubspot.api import update_deal_stage
        response = update_deal_stage(self.hubspot_deal_id, self.current_hubspot_gate, self)

    def _should_push_to_hubspot(self, old_stage):
        """
        Helper method to determine if we should push changes to HubSpot.
        Returns True if the gate has changed and we have a HubSpot deal ID.
        """
        return (
            self.hubspot_deal_id and
            self.current_hubspot_gate and
            old_stage != self.current_hubspot_gate
        )

    def get_gate_info(self):
        """
        Get HubSpot gate progress information for customer display.

        Returns dict with current gate info and progress through active gates,
        or None if no current gate is set.
        """
        if not self.current_hubspot_gate:
            return None

        current_gate = self.current_hubspot_gate
        current_gate_name = current_gate.get_customer_display_name()

        # Get all gates that should be included in progress tracking
        active_gates = ExternalAPIOrderIdentifier.objects.filter(
            pipeline_id=current_gate.pipeline_id,
            include_in_progress=True
        ).order_by('display_order')

        result = {
            'current_gate_name': current_gate_name,
            'current_gate_full_name': current_gate.stage_name,
            'is_in_progress': current_gate.include_in_progress,
            'gates': [],  # List of all gates with their status
        }

        # Build list of gates with their status
        current_index = None
        for idx, gate in enumerate(active_gates):
            gate_data = {
                'name': gate.get_customer_display_name(),
                'full_name': gate.stage_name,
                'is_current': gate.id == current_gate.id,
                'is_completed': False,  # We'll determine this below
            }

            if gate.id == current_gate.id:
                current_index = idx

            result['gates'].append(gate_data)

        # Mark completed gates (all gates before current)
        if current_index is not None:
            for i in range(current_index):
                result['gates'][i]['is_completed'] = True

        # Only calculate progress if current gate is part of active pipeline
        if current_gate.include_in_progress and current_index is not None:
            try:
                result['current_position'] = current_index + 1
                result['total_gates'] = len(active_gates)
                result['progress_percent'] = round(((current_index + 1) / len(active_gates)) * 100, 1)
            except ZeroDivisionError:
                pass

        return result

    def bulk_increment_parts_at_step(self, step_id):
        """Increment all parts at a specific step"""
        try:
            target_step = Steps.objects.get(id=step_id)
        except Steps.DoesNotExist:
            raise ValueError(f"Step with id {step_id} does not exist")

        parts_to_advance = self.parts.filter(step=target_step)
        advanced = 0

        import logging
        logger = logging.getLogger(__name__)

        for part in parts_to_advance:
            try:
                result = part.increment_step()
                if result in ["completed_workorder", "full_work_order_advanced"]:
                    advanced += 1
            except Exception as e:
                logger.warning(
                    f"Failed to increment part {part.id} in bulk operation: {e}",
                    exc_info=True
                )
                continue  # Skip failed parts, continue with others

        return {"advanced": advanced, "total": parts_to_advance.count()}

    def bulk_add_parts(self, part_type, step, quantity, part_status=PartsStatus.PENDING, work_order=None,
                       erp_id_start=1):
        """Add multiple parts to this order efficiently"""
        # Create parts without sampling evaluation
        parts = []
        for i in range(quantity):
            erp_id = f"{part_type.ID_prefix or 'P'}{erp_id_start + i:04d}"
            part = Parts(part_status=part_status, order=self, part_type=part_type, step=step, work_order=work_order,
                         archived=False, ERP_id=erp_id)
            parts.append(part)

        # Bulk create for efficiency
        created_parts = Parts.objects.bulk_create(parts)

        # Evaluate sampling for all new parts
        updates = []
        for part in created_parts:
            evaluator = SamplingFallbackApplier(part=part)
            result = evaluator.evaluate()

            part.requires_sampling = result.get("requires_sampling", False)
            part.sampling_rule = result.get("rule")
            part.sampling_ruleset = result.get("ruleset")
            part.sampling_context = result.get("context", {})
            updates.append(part)

        # Bulk update sampling fields
        Parts.objects.bulk_update(updates,
                                  ["requires_sampling", "sampling_rule", "sampling_ruleset", "sampling_context"])

        return {"created": len(created_parts), "parts": created_parts}

    def bulk_remove_parts(self, part_ids):
        """Remove parts from this order by setting order to None"""
        parts = Parts.objects.filter(id__in=part_ids, order=self)
        count = parts.update(order=None)
        return {"removed": count}

    def get_process_stages(self):
        """
        Get stage progression for order based on parts' current steps.

        Uses edge-based traversal (following DEFAULT edges) to order steps.
        Determines completion based on current part positions, not transition history.

        Returns:
            List of stage dicts with: name, is_completed, is_current, step_id, order
        """
        if not self.parts.exists():
            return []

        # Get the process from the work order
        work_orders = self.related_orders.filter(archived=False).select_related('process')
        if not work_orders.exists():
            return []

        first_wo = work_orders.first()
        if not first_wo or not first_wo.process:
            return []

        process = first_wo.process

        # Get ordered steps via edge traversal (happy path)
        ordered_steps = self._get_ordered_steps_via_edges(process)

        if not ordered_steps:
            # Fallback to ProcessStep.order if no edges defined
            process_steps = ProcessStep.objects.filter(
                process=process
            ).select_related('step').order_by('order')
            ordered_steps = [(ps.step, ps.order) for ps in process_steps]

        if not ordered_steps:
            return []

        # Build step_id -> order mapping for this process
        step_order_map = {step.id: order for step, order in ordered_steps}

        # Get all parts for this order (exclude completed/scrapped/cancelled)
        active_parts = self.parts.select_related('step').exclude(
            part_status__in=[PartsStatus.COMPLETED, PartsStatus.SCRAPPED, PartsStatus.CANCELLED]
        )
        total_active = active_parts.count()

        # Count parts at each step and track min/max order positions
        parts_at_step = {}  # step_id -> count
        max_part_order = -1  # Track furthest step any part has reached

        for part in active_parts:
            if part.step_id:
                parts_at_step[part.step_id] = parts_at_step.get(part.step_id, 0) + 1
                step_order = step_order_map.get(part.step_id)
                if step_order is not None and step_order > max_part_order:
                    max_part_order = step_order

        # Also check completed parts to see how far the order has progressed
        completed_count = self.parts.filter(part_status=PartsStatus.COMPLETED).count()
        if completed_count > 0:
            # Some parts completed the entire workflow
            max_part_order = max(max_part_order, len(ordered_steps))

        stages = []
        for step, order in ordered_steps:
            # is_current: At least one active part is at this step
            is_current = step.id in parts_at_step and parts_at_step[step.id] > 0

            # is_completed: No active parts at this step AND parts have progressed past it
            # A step is completed if it has no active parts and max_part_order > this order
            is_completed = not is_current and order < max_part_order

            stages.append({
                "name": step.name,
                "is_completed": is_completed,
                "is_current": is_current,
                "step_id": step.id,
                "order": order
            })

        return stages

    def _get_ordered_steps_via_edges(self, process):
        """
        Get steps in order by traversing DEFAULT edges from entry point.

        Returns list of (step, order) tuples, or empty list if no edges defined.
        """
        # Get entry step
        entry_ps = process.process_steps.filter(is_entry_point=True).select_related('step').first()
        if not entry_ps:
            return []

        # Get all default edges for this process
        edges = list(process.step_edges.filter(
            edge_type=EdgeType.DEFAULT
        ).select_related('from_step', 'to_step'))

        if not edges:
            return []

        # Build adjacency: from_step_id -> to_step
        next_step_map = {edge.from_step_id: edge.to_step for edge in edges}

        # Traverse from entry point following default edges
        ordered = []
        current = entry_ps.step
        visited = set()
        order = 0

        while current and current.id not in visited:
            visited.add(current.id)
            ordered.append((current, order))
            order += 1
            current = next_step_map.get(current.id)

        return ordered

    def get_detailed_stage_info(self):
        """
        Get detailed stage information with sampling data.

        Extends get_process_stages() with sampling information per step.
        """
        stages = self.get_process_stages()

        # Enhance with sampling information
        for stage in stages:
            step_id = stage['step_id']

            parts_at_step = self.parts.filter(step_id=step_id)
            sampled_parts = parts_at_step.filter(requires_sampling=True)
            total_at_step = parts_at_step.count()

            stage['sampling_info'] = {
                'total_parts': total_at_step,
                'sampled_parts': sampled_parts.count(),
                'sampling_rate': (sampled_parts.count() / total_at_step * 100) if total_at_step > 0 else 0
            }

        return stages

    # =========================================================================
    # NOTES TIMELINE METHODS
    # =========================================================================

    def add_note(self, user, message, visibility='visible'):
        """Add a note to the timeline (newest first)."""
        from django.utils import timezone

        if not message or not message.strip():
            raise ValueError("Note message cannot be empty")

        user_name = f"{user.first_name} {user.last_name}".strip() if user else "System"
        if not user_name:
            user_name = user.username if user else "System"

        header = f"[{timezone.now().isoformat()} | {user_name} | {visibility}]"
        new_note = f"{header}\n{message.strip()}"

        if self.customer_note:
            self.customer_note = new_note + "\n---\n" + self.customer_note
        else:
            self.customer_note = new_note

        return {'timestamp': timezone.now().isoformat(), 'user': user_name, 'visibility': visibility, 'message': message.strip()}

    def get_latest_note(self, customer_view=False):
        """Get the most recent note."""
        notes = self.get_notes(customer_view=customer_view)
        return notes[0] if notes else None

    def get_notes(self, customer_view=False):
        """Parse all notes from the timeline."""
        if not self.customer_note:
            return []

        notes = []
        for block in self.customer_note.split('\n---\n'):
            lines = block.strip().split('\n', 1)
            if lines[0].startswith('[') and ']' in lines[0]:
                parts = lines[0][1:lines[0].index(']')].split(' | ')
                if len(parts) == 3:
                    note = {
                        'timestamp': parts[0],
                        'user': parts[1],
                        'visibility': parts[2],
                        'message': lines[1] if len(lines) > 1 else ''
                    }
                    if not customer_view or note['visibility'] == 'visible':
                        notes.append(note)
            elif block.strip():
                # Legacy format - treat as visible note
                notes.append({'timestamp': None, 'user': 'Unknown', 'visibility': 'visible', 'message': block.strip()})

        return notes


class WorkOrderStatus(models.TextChoices):
    PENDING = 'PENDING', "Pending"
    IN_PROGRESS = 'IN_PROGRESS', "In progress"
    COMPLETED = 'COMPLETED', "Completed"
    ON_HOLD = 'ON_HOLD', "On hold"
    CANCELLED = 'CANCELLED', "Cancelled"
    WAITING_FOR_OPERATOR = 'WAITING_FOR_OPERATOR', "Waiting for operator"

    def __str__(self):
        """Returns the order name for human-readable use in admin or logs."""
        return self.name


class WorkOrderPriority(models.IntegerChoices):
    """Priority levels for work orders. Lower number = higher priority."""
    URGENT = 1, "Urgent"
    HIGH = 2, "High"
    NORMAL = 3, "Normal"
    LOW = 4, "Low"


class WorkOrder(SecureModel):
    """
    Represents a production Work Order derived from a customer Order.

    Work Orders are internal job assignments typically associated with a factory operator.
    Each is traceable to its parent `Orders` record and includes both estimated and actual
    timing data for operational tracking and audit.

    This model supports lifecycle management via statuses and soft notes fields.
    """

    workorder_status = models.CharField(max_length=50, choices=WorkOrderStatus.choices, default=WorkOrderStatus.PENDING)
    """Current status of the work order (e.g., in progress, completed)."""

    priority = models.IntegerField(
        choices=WorkOrderPriority.choices,
        default=WorkOrderPriority.NORMAL,
        help_text="Work order priority. Lower number = higher priority for scheduling."
    )
    """Priority level for scheduling and queue ordering."""

    quantity = models.IntegerField(default=1)

    documents = GenericRelation('Tracker.Documents')
    """Optional document relating to this Work Order"""

    ERP_id = models.CharField(max_length=50)
    """External ERP identifier used to sync or reference the work order."""

    related_order = models.ForeignKey('Orders', on_delete=models.PROTECT, related_name='related_orders', null=True,
                                      blank=True)
    """The customer-facing order this work order is derived from."""

    process = models.ForeignKey('Processes', on_delete=models.SET_NULL, null=True, blank=True,
                                related_name='work_orders')
    """The manufacturing process this work order follows. Locked at creation for version control."""

    expected_completion = models.DateField(null=True, blank=True)
    """Projected calendar date by which the work order should be complete."""

    expected_duration = models.DurationField(null=True, blank=True)
    """Planned time span estimated for completing this work order."""

    true_completion = models.DateField(null=True, blank=True)
    """Actual calendar date when the work was completed."""

    true_duration = models.DurationField(null=True, blank=True)
    """Measured time taken to complete the work order."""

    notes = models.TextField(max_length=500, null=True, blank=True)
    """Optional notes or remarks logged during execution or review."""

    class Meta:
        verbose_name = "Work Order"
        verbose_name_plural = "Work Orders"
        ordering = ["priority", "-created_at"]
        indexes = [
            models.Index(fields=['workorder_status', 'created_at'], name='workorder_status_created_idx'),
            models.Index(fields=['related_order', 'workorder_status'], name='workorder_order_status_idx'),
            models.Index(fields=['process', 'workorder_status'], name='workorder_process_status_idx'),
            models.Index(fields=['priority', 'workorder_status'], name='workorder_priority_status_idx'),
        ]

    def __str__(self):
        """Returns a string representation for admin and logs."""
        return f"WO-{self.ERP_id} ({self.workorder_status})"

    def save(self, *args, **kwargs):
        """Enhanced save with sampling lifecycle management"""
        is_new = self.pk is None
        old_status = None

        if not is_new:
            try:
                old_instance = WorkOrder.objects.get(pk=self.pk)
                old_status = old_instance.workorder_status
            except WorkOrder.DoesNotExist:
                pass

        super().save(*args, **kwargs)

        # Update related order's expected completion date
        if self.related_order and self.expected_completion:
            current_order_completion = self.related_order.estimated_completion

            # Set to the maximum of current order date and this work order's date
            if current_order_completion is None:
                new_completion = self.expected_completion
            else:
                new_completion = max(current_order_completion, self.expected_completion)

            # Only update if the date actually changed to avoid unnecessary saves
            if self.related_order.estimated_completion != new_completion:
                self.related_order.estimated_completion = new_completion
                self.related_order.save(update_fields=['estimated_completion'])

        # Handle status transitions
        if old_status != self.workorder_status:
            self._handle_status_change(old_status)

    def _handle_status_change(self, old_status):
        """Handle work order status changes affecting sampling"""
        if self.workorder_status == WorkOrderStatus.IN_PROGRESS and old_status == WorkOrderStatus.PENDING:
            # Initialize sampling for all parts when work order starts
            self._initialize_sampling()

        elif self.workorder_status == WorkOrderStatus.COMPLETED:
            # Generate final sampling analytics
            self._generate_final_sampling_report()

        elif self.workorder_status == WorkOrderStatus.ON_HOLD:
            # Pause any active fallback triggers
            self._pause_sampling_triggers()

    def _initialize_sampling(self):
        """Initialize sampling evaluation for all parts in work order"""
        parts_without_sampling = self.parts.filter(requires_sampling__isnull=True)

        if parts_without_sampling.exists():
            self._bulk_evaluate_sampling(list(parts_without_sampling))

    def _bulk_evaluate_sampling(self, parts_list):
        """Evaluate sampling for multiple parts efficiently"""
        updates = []
        for part in parts_list:
            evaluator = SamplingFallbackApplier(part=part)
            result = evaluator.evaluate()

            part.requires_sampling = result.get("requires_sampling", False)
            part.sampling_rule = result.get("rule")
            part.sampling_ruleset = result.get("ruleset")
            part.sampling_context = result.get("context", {})
            updates.append(part)

        # Bulk update sampling fields
        Parts.objects.bulk_update(updates,
                                  ["requires_sampling", "sampling_rule", "sampling_ruleset", "sampling_context"])

    def _generate_final_sampling_report(self):
        """Generate comprehensive sampling report for completed work order"""
        # This could create a summary document or trigger reporting
        pass

    def _pause_sampling_triggers(self):
        """Pause active sampling triggers when work order is on hold"""
        SamplingTriggerState.objects.filter(work_order=self, active=True).update(active=False)

    def create_parts_batch(self, part_type, step, quantity=None):
        """Create parts in batch with sampling evaluation.

        This method is idempotent - it won't create duplicate parts if called
        multiple times. Parts are identified by their ERP_id which follows the
        pattern: {work_order.ERP_id}-{part_type.ID_prefix}{sequence_number}
        """
        quantity = quantity or self.quantity

        # Check for existing parts to make this idempotent
        existing_erp_ids = set(
            Parts.objects.filter(work_order=self)
            .values_list('ERP_id', flat=True)
        )

        # Create only parts that don't already exist
        parts_to_create = []
        for i in range(quantity):
            erp_id = f"{self.ERP_id}-{part_type.ID_prefix or 'P'}{i + 1:04d}"
            if erp_id not in existing_erp_ids:
                part = Parts(
                    tenant=self.tenant,  # Inherit tenant from work order
                    work_order=self,
                    part_type=part_type,
                    step=step,
                    ERP_id=erp_id,
                    part_status=PartsStatus.PENDING
                )
                parts_to_create.append(part)

        # Bulk create only new parts
        if parts_to_create:
            Parts.objects.bulk_create(parts_to_create)

        # Get all parts for this work order and part type (existing + new)
        fresh_parts = list(Parts.objects.filter(work_order=self, part_type=part_type, step=step).order_by('id'))

        # Evaluate sampling for all parts
        self._bulk_evaluate_sampling(fresh_parts)

        return fresh_parts

    @classmethod
    def process_csv_date(cls, date_string):
        """Process various date formats from CSV uploads"""
        from datetime import datetime
        from django.utils.dateparse import parse_date

        if not date_string or str(date_string).strip() == '':
            return None

        # Try standard ISO format first
        parsed = parse_date(str(date_string).strip())
        if parsed:
            return parsed

        # Try various formats
        date_formats = ["%b %d", "%B %d", "%Y-%m-%d", "%m/%d/%Y", "%d/%m/%Y"]

        for fmt in date_formats:
            try:
                dt = datetime.strptime(str(date_string).strip(), fmt)
                today = datetime.today()
                year = today.year

                # For formats without year, assume next year if date has passed
                if fmt in ["%b %d", "%B %d"]:
                    if dt.month < today.month or (dt.month == today.month and dt.day < today.day):
                        year += 1
                    return dt.replace(year=year).date()
                else:
                    return dt.date()
            except (ValueError, TypeError):
                continue

        raise ValueError(f"Invalid date format: {date_string}")

    @classmethod
    def create_from_csv_row(cls, row_data, user=None):
        """Create or update work order from CSV row data"""
        erp_id = row_data.get('ERP_id')
        if not erp_id:
            raise ValueError("ERP_id is required")

        # Process related order lookup
        related_order = None
        related_order_erp = row_data.get("related_order_erp_id")
        if related_order_erp:
            try:
                related_order = Orders.objects.get(ERP_id=related_order_erp)
            except Orders.DoesNotExist:
                pass  # Continue without related order

        # Process expected completion date
        expected_completion = None
        warnings = []
        if row_data.get("expected_completion"):
            try:
                expected_completion = cls.process_csv_date(row_data["expected_completion"])
            except ValueError as e:
                warnings.append(f"Invalid date format: {e}")

        # Create or update work order
        work_order, created = cls.objects.update_or_create(ERP_id=erp_id,
                                                           defaults={'quantity': row_data.get('quantity', 1),
                                                                     'expected_completion': expected_completion,
                                                                     'notes': row_data.get('notes', ''),
                                                                     'workorder_status': row_data.get(
                                                                         'workorder_status', WorkOrderStatus.PENDING),
                                                                     'related_order': related_order,
                                                                     'expected_duration': row_data.get(
                                                                         'expected_duration'),
                                                                     'true_duration': row_data.get('true_duration')})

        return work_order, created, warnings

    @classmethod
    def bulk_create_from_csv(cls, file_data, user=None):
        """Process CSV file and create multiple work orders"""
        results = []

        for i, row in enumerate(file_data, start=1):
            try:
                work_order, created, warnings = cls.create_from_csv_row(row, user)
                result = {"row": i, "status": "success" if created else "updated", "id": work_order.id}
                if warnings:
                    result["warnings"] = warnings
                results.append(result)

            except Exception as e:
                results.append({"row": i, "status": "error", "errors": str(e)})

        return results


class Parts(SecureModel):
    """
    Represents an individual part undergoing a manufacturing process.

    Parts are linked to Orders, Work Orders, and a specific PartType and Step.
    This model tracks a part's lifecycle status, position in the process chain,
    and is capable of version-safe archiving and step progression.

    Lifecycle transitions and traceability are critical for quality control and compliance audits.
    """

    class Meta:
        verbose_name_plural = 'Parts'
        verbose_name = 'Part'
        indexes = [
            models.Index(fields=['part_status', 'work_order'], name='parts_status_workorder_idx'),
            models.Index(fields=['part_status', 'step'], name='parts_status_step_idx'),
            models.Index(fields=['work_order', 'step'], name='parts_workorder_step_idx'),
            models.Index(fields=['order', 'part_status'], name='parts_order_status_idx'),
        ]

    ERP_id = models.CharField(max_length=50)
    """External ERP identifier used to reference this part in outside systems."""

    documents = GenericRelation('Tracker.Documents')

    part_type = models.ForeignKey(PartTypes, on_delete=models.SET_NULL, null=True, blank=True, related_name='parts')
    """The part type defining process steps and classification of this part."""

    step = models.ForeignKey(Steps, on_delete=models.SET_NULL, null=True, blank=True, related_name='active_parts')
    """The current step the part is undergoing in its manufacturing process."""

    order = models.ForeignKey(Orders, on_delete=models.CASCADE, related_name='parts', null=True, blank=True)
    """Reference to the customer Order that this part belongs to."""

    part_status = models.CharField(max_length=50, choices=PartsStatus.choices, default=PartsStatus.PENDING)
    """Lifecycle status indicating part progress through the workflow."""

    work_order = models.ForeignKey(WorkOrder, on_delete=models.SET_NULL, null=True, blank=True, related_name='parts')
    """Optional reference to the internal Work Order this part is attached to."""

    requires_sampling = models.BooleanField(default=False)
    """Whether this part requires quality inspection at its current step, determined by SamplingRule evaluation."""

    sampling_rule = models.ForeignKey(SamplingRule, null=True, blank=True, on_delete=models.SET_NULL,
                                      related_name="sampled_parts")
    """The specific sampling rule that triggered inspection for this part."""

    sampling_ruleset = models.ForeignKey(SamplingRuleSet, null=True, blank=True, on_delete=models.SET_NULL,
                                         related_name="sampled_parts")
    """The full sampling rule set used to evaluate this part for inspection."""

    sampling_context = models.JSONField(default=dict, blank=True)
    """Context data for sampling decisions, used by SamplingFallbackApplier."""

    total_rework_count = models.IntegerField(default=0)
    """Total number of times this part has been reworked across all steps."""

    # =========================================================================
    # ITAR / Export Control Fields
    # =========================================================================
    itar_controlled = models.BooleanField(
        default=False,
        help_text="Part is ITAR-controlled defense article (22 CFR 121)"
    )
    """Indicates part is subject to ITAR export restrictions (USML item)."""

    eccn = models.CharField(
        max_length=20,
        blank=True,
        help_text="Export Control Classification Number (e.g., EAR99, 9A004)"
    )
    """
    ECCN from Commerce Control List for EAR-controlled items.
    Inherited from PartType by default, can be overridden per part.
    """

    export_license_required = models.BooleanField(
        default=False,
        help_text="Whether export license is required for this specific part"
    )
    """Cached determination of whether license is needed based on ECCN + destination."""

    country_of_origin = models.CharField(
        max_length=3,
        blank=True,
        help_text="ISO 3166-1 alpha-3 country code for country of origin"
    )
    """Country where part was manufactured - relevant for FMS and re-export."""

    # =========================================================================
    # FPI (First Piece Inspection) Tracking
    # =========================================================================
    is_fpi_candidate = models.BooleanField(
        default=False,
        help_text="Whether this part is designated as a First Piece Inspection candidate"
    )
    """Marks this part as the FPI candidate for setup verification."""

    fpi_override_reason = models.CharField(
        max_length=200,
        blank=True,
        help_text="Reason if FPI was overridden or waived"
    )
    """Reason for waiving or overriding FPI requirement on this part."""

    # ===== WORKFLOW ENGINE METHODS (Phase 1) =====

    def _check_cycle_limit(self, target_step):
        """
        Check if part has exceeded max visits for target step.
        Returns escalation_step if limit exceeded, else target_step.

        Used for rework loop control - after N failures, route to scrap decision
        instead of allowing endless rework cycles.
        """
        if target_step is None or target_step.max_visits is None:
            return target_step

        current_visits = StepExecution.get_visit_count(self, target_step)

        if current_visits >= target_step.max_visits:
            # Limit exceeded - route to escalation (e.g., scrap decision)
            # Get escalation edge from StepEdge
            process = self.work_order.process if self.work_order else None
            if process:
                escalation_edge = StepEdge.objects.filter(
                    process=process,
                    from_step=target_step,
                    edge_type=EdgeType.ESCALATION
                ).first()
                if escalation_edge:
                    return escalation_edge.to_step
            # No escalation defined - return None to trigger completion/error
            return None

        return target_step

    def _get_edge(self, from_step, edge_type):
        """Get a StepEdge for the current process context."""
        process = self.work_order.process if self.work_order else None
        if not process:
            return None
        edge = StepEdge.objects.filter(
            process=process,
            from_step=from_step,
            edge_type=edge_type
        ).first()
        return edge.to_step if edge else None

    def get_next_step(self, decision_result=None):
        """
        Determine next step based on current step configuration.
        Supports linear flow, decision branching, and cycle limits.

        Args:
            decision_result: 'pass', 'fail', 'default', 'alternate', or measurement value.
                             If None, will look up from QualityReport for qa_result decisions.

        Returns:
            Steps instance or None if terminal/completed.
        """
        current = self.step

        if not current:
            return None

        # Terminal step - no next
        if current.is_terminal:
            return None

        # Decision point - route based on result
        if current.is_decision_point:
            if current.decision_type == 'qa_result':
                # Use latest QualityReport result if not provided
                if decision_result is None:
                    from .qms import QualityReports
                    latest_qr = QualityReports.objects.filter(
                        part=self, step=current
                    ).order_by('-created_at').first()
                    if not latest_qr:
                        raise DecisionDataMissing(
                            f"QualityReport required for qa_result decision at step '{current.name}'"
                        )
                    decision_result = latest_qr.status

                if str(decision_result).upper() == 'PASS':
                    return self._check_cycle_limit(self._get_edge(current, EdgeType.DEFAULT))
                else:
                    return self._check_cycle_limit(self._get_edge(current, EdgeType.ALTERNATE))

            elif current.decision_type == 'measurement':
                # Evaluate measurement against threshold from StepEdge condition
                process = self.work_order.process if self.work_order else None
                if process:
                    # Get edges to check conditions
                    edges = StepEdge.objects.filter(
                        process=process,
                        from_step=current
                    ).select_related('condition_measurement')

                    for edge in edges:
                        if edge.condition_measurement and edge.condition_value is not None:
                            # Get measurement value if not provided
                            if decision_result is None:
                                from .qms import MeasurementResult
                                latest_mr = MeasurementResult.objects.filter(
                                    quality_report__part=self,
                                    measurement_definition=edge.condition_measurement
                                ).order_by('-created_at').first()
                                decision_result = float(latest_mr.actual_value) if latest_mr else 0

                            threshold = float(edge.condition_value)
                            if edge.condition_operator == 'gte':
                                passed = float(decision_result) >= threshold
                            elif edge.condition_operator == 'lte':
                                passed = float(decision_result) <= threshold
                            else:  # eq
                                passed = float(decision_result) == threshold

                            if passed and edge.edge_type == EdgeType.DEFAULT:
                                return self._check_cycle_limit(edge.to_step)
                            elif not passed and edge.edge_type == EdgeType.ALTERNATE:
                                return self._check_cycle_limit(edge.to_step)

                # Fallback to default edge if no condition matched
                return self._check_cycle_limit(self._get_edge(current, EdgeType.DEFAULT))

            elif current.decision_type == 'manual':
                # Require explicit decision_result
                if decision_result in ('default', 'pass'):
                    return self._check_cycle_limit(self._get_edge(current, EdgeType.DEFAULT))
                elif decision_result in ('alternate', 'fail'):
                    return self._check_cycle_limit(self._get_edge(current, EdgeType.ALTERNATE))
                else:
                    raise ValueError("Manual decision required: 'default'/'pass' or 'alternate'/'fail'")

        # Non-decision point: use default edge
        default_next = self._get_edge(current, EdgeType.DEFAULT)
        if default_next:
            return self._check_cycle_limit(default_next)

        # Fallback: get next step by ProcessStep order
        process = self.work_order.process if self.work_order else None
        if process:
            current_ps = ProcessStep.objects.filter(process=process, step=current).first()
            if current_ps:
                next_ps = ProcessStep.objects.filter(
                    process=process,
                    order=current_ps.order + 1
                ).first()
                if next_ps:
                    return self._check_cycle_limit(next_ps.step)

        return None

    def _get_operator_for_step(self, step, previous_operator):
        """
        Determine operator assignment based on step's revisit_assignment rule.
        Returns User or None (unassigned, anyone can pick up).

        Rules:
        - 'any': No assignment, anyone can pick it up
        - 'same': Assign to same operator as previous visit
        - 'different': Exclude previous operators (returns None, filtering done at assignment)
        - 'role': Must be someone with specific role (returns None, filtering done at assignment)
        """
        if step.revisit_assignment == 'same':
            return previous_operator
        elif step.revisit_assignment == 'different':
            # Return None - UI/assignment system will filter available operators
            # Previous operators can be queried from StepExecution
            return None
        elif step.revisit_assignment == 'role':
            # Return None - UI will filter by step.revisit_role
            return None
        else:  # 'any'
            return None

    def increment_step(self, operator=None, decision_result=None):
        """
        Advance part to next step using workflow engine logic.

        Supports:
        - Linear flow (legacy order+1)
        - Decision branching (qa_result, measurement, manual)
        - Cycle limits with escalation
        - StepExecution lifecycle tracking
        - Batch advancement for work orders

        Args:
            operator: User who performed the transition. If None, logged as system/automated.
            decision_result: For decision points - 'pass', 'fail', 'default', 'alternate', or measurement value.

        Returns:
            str: "completed" if terminal/final step reached,
                 "marked_ready" if waiting for others,
                 "advanced" if step advanced,
                 "escalated" if routed to escalation due to cycle limit.

        Raises:
            ValueError: If step advancement is blocked by validation requirements.
        """
        from django.utils import timezone
        from .qms import StepTransitionLog

        if not self.step or not self.part_type:
            raise ValueError("Current step or part type is missing.")

        # Get current execution for validation
        current_execution = StepExecution.get_current_execution(self)

        # Validate advancement is allowed before proceeding
        if current_execution and self.work_order:
            can_advance, blockers = self.step.can_advance_from_step(
                current_execution,
                self.work_order
            )
            if not can_advance:
                raise ValueError(f"Cannot advance: {', '.join(blockers)}")
        if current_execution:
            current_execution.exited_at = timezone.now()
            current_execution.completed_by = operator
            current_execution.status = 'completed'
            current_execution.decision_result = str(decision_result) if decision_result else ''

        # Determine next step using workflow logic
        next_step = self.get_next_step(decision_result)

        # Handle terminal/final step
        if next_step is None:
            if self.step.is_terminal:
                # Use terminal_status to set part status
                # Maps Step.terminal_status values to PartsStatus enum
                status_map = {
                    'completed': PartsStatus.COMPLETED,
                    'shipped': PartsStatus.SHIPPED,
                    'stock': PartsStatus.IN_STOCK,
                    'scrapped': PartsStatus.SCRAPPED,
                    'returned': PartsStatus.CANCELLED,
                    'awaiting_pickup': PartsStatus.AWAITING_PICKUP,
                    'core_banked': PartsStatus.CORE_BANKED,
                    'rma_closed': PartsStatus.RMA_CLOSED,
                }
                self.part_status = status_map.get(
                    self.step.terminal_status,
                    PartsStatus.COMPLETED
                )
            else:
                # Legacy is_last_step or no next found
                self.part_status = PartsStatus.COMPLETED

            if current_execution:
                current_execution.save()

            self.save()

            # Also log to StepTransitionLog for backwards compatibility
            StepTransitionLog.objects.create(part=self, step=self.step, operator=operator)

            # Cascade: check if WorkOrder should auto-complete
            self._cascade_work_order_completion()

            return "completed"

        # Check if this was an escalation (cycle limit exceeded)
        was_escalated = False
        if self.step.is_decision_point or self.step.max_visits:
            process = self.work_order.process if self.work_order else None
            if process:
                # Check if next_step matches alternate or escalation edge
                alt_edge = StepEdge.objects.filter(
                    process=process, from_step=self.step, edge_type=EdgeType.ALTERNATE
                ).first()
                esc_edge = StepEdge.objects.filter(
                    process=process, from_step=self.step, edge_type=EdgeType.ESCALATION
                ).first()
                was_escalated = (
                    (alt_edge and alt_edge.to_step == next_step) or
                    (esc_edge and esc_edge.to_step == next_step)
                )

        # Record next_step on current execution before saving
        if current_execution:
            current_execution.next_step = next_step
            current_execution.save()

        # For batch processes, check if we should wait for other parts
        # Use requires_batch_completion flag instead of is_decision_point
        if self.work_order and getattr(self.step, 'requires_batch_completion', False):
            # Mark this part ready
            self.part_status = PartsStatus.READY_FOR_NEXT_STEP
            self.save()

            # Check if all parts at this step are ready
            other_parts_pending = Parts.objects.filter(
                work_order=self.work_order,
                part_type=self.part_type,
                step=self.step
            ).exclude(part_status=PartsStatus.READY_FOR_NEXT_STEP)

            if other_parts_pending.exists():
                return "marked_ready"

            # All parts are ready. Check if step allows advancement.
            if hasattr(self.step, 'can_advance_step') and not self.step.can_advance_step(
                work_order=self.work_order, step=self.step
            ):
                return "marked_ready"

            # Bulk-advance all parts
            ready_parts = list(Parts.objects.filter(
                work_order=self.work_order,
                part_type=self.part_type,
                step=self.step,
                part_status=PartsStatus.READY_FOR_NEXT_STEP
            ))

            transition_logs = []
            step_executions = []

            for part in ready_parts:
                part.step = next_step
                part.part_status = PartsStatus.IN_PROGRESS
                evaluator = SamplingFallbackApplier(part=part)
                result = evaluator.evaluate()
                part.requires_sampling = result.get("requires_sampling", False)
                part.sampling_rule = result.get("rule")
                part.sampling_ruleset = result.get("ruleset")
                part.sampling_context = result.get("context", {})

                # Queue legacy transition log
                transition_logs.append(StepTransitionLog(part=part, step=next_step, operator=operator))

                # Queue new StepExecution
                visit_number = StepExecution.get_visit_count(part, next_step) + 1
                assigned_operator = part._get_operator_for_step(next_step, operator)
                step_executions.append(StepExecution(
                    part=part,
                    step=next_step,
                    visit_number=visit_number,
                    assigned_to=assigned_operator,
                    status='pending'
                ))

            Parts.objects.bulk_update(ready_parts, [
                "step", "part_status", "requires_sampling",
                "sampling_rule", "sampling_ruleset", "sampling_context"
            ])

            StepTransitionLog.objects.bulk_create(transition_logs)
            StepExecution.objects.bulk_create(step_executions)

            return "escalated" if was_escalated else "advanced"

        # Individual part advancement (decision points or no work order)
        visit_number = StepExecution.get_visit_count(self, next_step) + 1
        assigned_operator = self._get_operator_for_step(next_step, operator)

        StepExecution.objects.create(
            part=self,
            step=next_step,
            visit_number=visit_number,
            assigned_to=assigned_operator,
            status='pending'
        )

        # Move to next step first so sampling evaluation sees the new step
        self.step = next_step
        self.part_status = PartsStatus.IN_PROGRESS

        # Update sampling for the new step
        evaluator = SamplingFallbackApplier(part=self)
        result = evaluator.evaluate()
        self.requires_sampling = result.get("requires_sampling", False)
        self.sampling_rule = result.get("rule")
        self.sampling_ruleset = result.get("ruleset")
        self.sampling_context = result.get("context", {})
        self.save()

        # Legacy log
        StepTransitionLog.objects.create(part=self, step=next_step, operator=operator)

        return "escalated" if was_escalated else "advanced"

    def _cascade_work_order_completion(self):
        """
        Check if all parts in work order have reached terminal status.
        If so, auto-complete the WorkOrder.

        Called after a part reaches a terminal step.
        """
        from django.utils import timezone

        wo = self.work_order
        if not wo:
            return

        # Terminal statuses for parts
        terminal_statuses = [
            PartsStatus.COMPLETED,
            PartsStatus.SCRAPPED,
            PartsStatus.CANCELLED,
        ]

        # Check if any parts are NOT at terminal status
        non_terminal_parts = wo.parts.exclude(part_status__in=terminal_statuses)

        if non_terminal_parts.exists():
            # Not all parts done yet
            return

        # All parts at terminal status - determine WO status
        all_parts_count = wo.parts.count()
        completed_count = wo.parts.filter(part_status=PartsStatus.COMPLETED).count()
        scrapped_count = wo.parts.filter(part_status=PartsStatus.SCRAPPED).count()

        if scrapped_count == all_parts_count:
            # All parts scrapped - mark as cancelled
            wo.workorder_status = WorkOrderStatus.CANCELLED
        else:
            # At least some parts completed
            wo.workorder_status = WorkOrderStatus.COMPLETED

        wo.true_completion = timezone.now().date()
        wo.save(update_fields=['workorder_status', 'true_completion'])

    def has_quality_errors(self):
        """Check if part has any quality errors"""
        return self.error_reports.filter(status='FAIL').exists()

    def get_latest_quality_status(self):
        """Get the most recent quality report status"""
        latest_report = self.error_reports.order_by('-created_at').first()
        return latest_report.status if latest_report else None

    def get_sampling_display_info(self):
        """Get sampling information for display purposes"""
        return {'requires_sampling': self.requires_sampling,
                'sampling_rule_type': self.sampling_rule.rule_type if self.sampling_rule else None,
                'sampling_rule_value': self.sampling_rule.value if self.sampling_rule else None,
                'ruleset_name': self.sampling_ruleset.name if self.sampling_ruleset else None,
                'is_fallback_active': bool(
                    SamplingTriggerState.objects.filter(work_order=self.work_order, step=self.step,
                                                        active=True).exists()) if self.work_order and self.step else False}

    def get_work_order_display_info(self):
        """Get work order information for display"""
        if not self.work_order:
            return None

        return {'erp_id': self.work_order.ERP_id, 'status': self.work_order.workorder_status,
                'quantity': self.work_order.quantity, 'expected_completion': self.work_order.expected_completion}

    def get_sampling_history(self):
        """Get complete sampling history for this part"""
        return {'current_sampling': {'requires_sampling': self.requires_sampling,
                                     'rule': {'id': self.sampling_rule.id, 'rule_type': self.sampling_rule.rule_type,
                                              'value': self.sampling_rule.value,
                                              'order': self.sampling_rule.order} if self.sampling_rule else None,
                                     # ✅ Convert to dict
                                     'ruleset': {'id': self.sampling_ruleset.id, 'name': self.sampling_ruleset.name,
                                                 'version': self.sampling_ruleset.version,
                                                 'active': self.sampling_ruleset.active} if self.sampling_ruleset else None,
                                     # ✅ Convert to dict
                                     'context': self.sampling_context}, 'quality_reports': list(
            self.error_reports.all().values('status', 'created_at', 'sampling_method', 'description')),
                'audit_logs': list(SamplingAuditLog.objects.filter(part=self).values('sampling_decision', 'timestamp',
                                                                                     'ruleset_type')) if 'SamplingAuditLog' in globals() else []}

    def can_rollback_step(self, operator=None):
        """
        Check if this part can be rolled back to the previous step.

        Returns:
            tuple: (can_rollback: bool, reason: str, requires_approval: bool)
        """
        from django.utils import timezone
        from .qms import StepOverride, OverrideStatus, BlockType

        if not self.step:
            return (False, "Part has no current step", False)

        # Get the most recent completed execution for current step
        current_execution = StepExecution.objects.filter(
            part=self,
            step=self.step,
            status='completed'
        ).order_by('-exited_at').first()

        if not current_execution:
            return (False, "No completed execution found for current step", False)

        # Get the previous step execution (the one that led to current)
        previous_execution = StepExecution.objects.filter(
            part=self,
            next_step=self.step,
            status='completed'
        ).order_by('-exited_at').first()

        if not previous_execution:
            # Check if we're at the first step
            first_step = None
            if self.part_type and self.work_order and self.work_order.process:
                # Get first step via ProcessStep ordering
                first_process_step = ProcessStep.objects.filter(
                    process=self.work_order.process
                ).order_by('order').first()
                if first_process_step:
                    first_step = first_process_step.step

            if self.step == first_step:
                return (False, "Cannot rollback from the first step", False)
            return (False, "No previous step execution found", False)

        # Check undo window
        undo_window_minutes = getattr(self.step, 'undo_window_minutes', 15)
        if current_execution.exited_at:
            elapsed = timezone.now() - current_execution.exited_at
            elapsed_minutes = elapsed.total_seconds() / 60

            if elapsed_minutes > undo_window_minutes:
                return (
                    False,
                    f"Undo window expired ({undo_window_minutes} minutes)",
                    False
                )

        # Check if rollback requires approval
        requires_approval = getattr(self.step, 'rollback_requires_approval', True)

        if requires_approval:
            # Check for existing approved override for this execution
            approved_override = StepOverride.objects.filter(
                step_execution=current_execution,
                block_type=BlockType.ROLLBACK,
                status=OverrideStatus.APPROVED,
                used=False
            ).first()

            if approved_override:
                # Mark the time-sensitive check
                if approved_override.expires_at and approved_override.expires_at < timezone.now():
                    return (False, "Rollback approval has expired", True)
                return (True, "Rollback approved", False)  # Has approval, doesn't need more

            return (True, "Rollback requires approval", True)

        return (True, "Rollback allowed", False)

    def rollback_step(self, operator, reason=None, override_id=None):
        """
        Roll back this part to the previous step in the workflow.

        This is configurable per step via:
        - undo_window_minutes: Time window during which rollback is allowed
        - rollback_requires_approval: Whether supervisor approval is required

        Args:
            operator: User performing the rollback
            reason: Justification for the rollback (required if no override)
            override_id: ID of pre-approved StepOverride (optional)

        Returns:
            dict: {
                'success': bool,
                'message': str,
                'previous_step': Steps instance if successful,
                'requires_approval': bool (if rollback needs approval)
            }

        Raises:
            ValueError: If rollback is not allowed or required data is missing.
        """
        from django.utils import timezone
        from .qms import StepTransitionLog, StepOverride, OverrideStatus, BlockType

        # Check if rollback is allowed
        can_rollback, message, requires_approval = self.can_rollback_step(operator)

        if not can_rollback:
            raise ValueError(f"Cannot rollback: {message}")

        # Get current and previous executions
        current_execution = StepExecution.objects.filter(
            part=self,
            step=self.step,
            status='completed'
        ).order_by('-exited_at').first()

        previous_execution = StepExecution.objects.filter(
            part=self,
            next_step=self.step,
            status='completed'
        ).order_by('-exited_at').first()

        if not current_execution or not previous_execution:
            raise ValueError("Cannot determine step execution history for rollback")

        previous_step = previous_execution.step

        # Handle approval workflow
        if requires_approval:
            if override_id:
                # Use provided override
                try:
                    override = StepOverride.objects.get(
                        id=override_id,
                        step_execution=current_execution,
                        block_type=BlockType.ROLLBACK,
                        status=OverrideStatus.APPROVED,
                        used=False
                    )
                    if override.expires_at and override.expires_at < timezone.now():
                        raise ValueError("Rollback approval has expired")

                    # Mark override as used
                    override.used = True
                    override.used_at = timezone.now()
                    override.save(update_fields=['used', 'used_at'])

                except StepOverride.DoesNotExist:
                    raise ValueError("Invalid or expired rollback override")
            else:
                # Create a pending override request
                if not reason or len(reason.strip()) < 10:
                    raise ValueError("Reason required for rollback approval request (minimum 10 characters)")

                override_expiry_hours = getattr(self.step, 'override_expiry_hours', 24)
                expires_at = timezone.now() + timezone.timedelta(hours=override_expiry_hours)

                StepOverride.objects.create(
                    step_execution=current_execution,
                    block_type=BlockType.ROLLBACK,
                    requested_by=operator,
                    reason=reason,
                    status=OverrideStatus.PENDING,
                    expires_at=expires_at
                )

                return {
                    'success': False,
                    'message': 'Rollback request submitted for approval',
                    'requires_approval': True,
                    'previous_step': previous_step
                }

        # Perform the rollback
        # 1. Mark current execution as rolled back
        current_execution.status = 'rolled_back'
        current_execution.save(update_fields=['status'])

        # 2. Create new execution for previous step (reopening it)
        visit_number = StepExecution.get_visit_count(self, previous_step) + 1
        new_execution = StepExecution.objects.create(
            part=self,
            step=previous_step,
            visit_number=visit_number,
            assigned_to=operator,  # Assign to person doing rollback
            status='in_progress',
            started_at=timezone.now()
        )

        # 3. Update part's current step
        old_step = self.step
        self.step = previous_step
        self.part_status = PartsStatus.IN_PROGRESS

        # 4. Re-evaluate sampling for the restored step
        evaluator = SamplingFallbackApplier(part=self)
        result = evaluator.evaluate()
        self.requires_sampling = result.get("requires_sampling", False)
        self.sampling_rule = result.get("rule")
        self.sampling_ruleset = result.get("ruleset")
        self.sampling_context = result.get("context", {})

        self.save()

        # 5. Log the rollback transition (with negative indication)
        StepTransitionLog.objects.create(
            part=self,
            step=previous_step,
            operator=operator
        )

        return {
            'success': True,
            'message': f'Rolled back from "{old_step.name}" to "{previous_step.name}"',
            'previous_step': previous_step,
            'requires_approval': False
        }

    @classmethod
    def get_filtered_queryset(cls, user=None, filters=None):
        """Get optimized queryset with common select_related/prefetch_related"""
        qs = cls.objects.select_related('part_type', 'step', 'order', 'work_order', 'sampling_rule',
                                        'sampling_ruleset').prefetch_related('error_reports')

        # Filter to only show customer's orders if user is in 'customer' group (tenant-scoped)
        if user and (user.has_tenant_group('customer') if hasattr(user, 'has_tenant_group') else False):
            qs = qs.filter(order__customer=user)

        return qs

    def save(self, *args, **kwargs):
        """Enhanced save method with sampling evaluation"""
        is_new = self.pk is None
        super().save(*args, **kwargs)

        # Evaluate sampling requirements for new parts
        if is_new and self.step and self.part_type and self.work_order:
            self._evaluate_initial_sampling()

    def _evaluate_initial_sampling(self):
        """Evaluate sampling requirements when part is first created"""
        evaluator = SamplingFallbackApplier(part=self)
        result = evaluator.evaluate()

        # Update sampling fields
        self.requires_sampling = result.get("requires_sampling", False)
        self.sampling_rule = result.get("rule")
        self.sampling_ruleset = result.get("ruleset")
        self.sampling_context = result.get("context", {})

        # Save without triggering recursion
        Parts.objects.filter(pk=self.pk).update(requires_sampling=self.requires_sampling,
                                                sampling_rule=self.sampling_rule,
                                                sampling_ruleset=self.sampling_ruleset,
                                                sampling_context=self.sampling_context)

    def __str__(self):
        """
        Returns a human-readable identifier combining ERP ID, Order, and PartType.
        """
        deal_name = getattr(self.order, 'name', 'Unknown Deal') if self.order else 'Unknown Deal'
        part_type_name = getattr(self.part_type, 'name', 'Unknown Part Type') if self.part_type else 'Unknown Part Type'
        return f"{self.ERP_id} {deal_name} {part_type_name}"


# Note: Equipment and Sampling models have been moved to mes_standard.py
# Note: ExternalAPIOrderIdentifier and HubSpotSyncLog are in integrations/hubspot.py
